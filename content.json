{"meta":{"title":"Devlog|デブログ","subtitle":"takadevエンジニアブログ","description":"takadevのエンジニアブログです。興味のある技術について日々発信していきます。","author":"takadev","url":"http://devlog.site"},"pages":[],"posts":[{"title":"ディープラーニング用語","slug":"machine-learning2","date":"2016-12-16T15:00:00.000Z","updated":"2016-12-17T09:41:09.000Z","comments":true,"path":"ディープラーニング/machine-learning2/","link":"","permalink":"http://devlog.site/ディープラーニング/machine-learning2/","excerpt":"わからない用語調べてみた先日、「ゼロから作るディープラーニング」をやっとこ読み終えました。かなり面白くて勉強になりました！ディープラーニングを始めてみようって人にはめちゃめちゃオススメです。理解が浅買った箇所をもう一度読み直してみようと思ってます。そんな中、分からなかった用語を調べたのでメモしておこうと思います。","content":"わからない用語調べてみた先日、「ゼロから作るディープラーニング」をやっとこ読み終えました。かなり面白くて勉強になりました！ディープラーニングを始めてみようって人にはめちゃめちゃオススメです。理解が浅買った箇所をもう一度読み直してみようと思ってます。そんな中、分からなかった用語を調べたのでメモしておこうと思います。 特徴量4章辺りで特徴量という言葉が出てきます。最初一瞬わからなかったんですが、前後の流れでなんとくこんな意味かなぁと思ってたらその通りでした。これは文字通り特徴の量のことで、よく画像認識なんかを扱う文脈で出てきます。「特徴量を記述する」とかっていう文章をたまに見かけますね。 特徴点特徴量と似ていますが、こちらも画像認識の文脈で使われ、言葉通り画像内のどこに特徴があるかを点で表したものです。 OpenCVOpneCV自体は本の中には多分出てこなかったと思いますが、画像認識周りでこの用語も出てくるので、前提知識として調べてみました。 OpenCV（オープンシーヴィ、英語: Open Source Computer Vision Library）とはインテルが開発・公開したオープンソースのコンピュータビジョン向けライブラリ wiki引用 画像を扱う便利なオープンソースのライブラリですね。まぁこれもなんとなく想像はできますよね。 SIFTScale-Invariant Feature Transformの頭文字を取ってSIFTです。SIFTは画像認識のためのアルゴリズムの一つで、特徴点の検出や特徴量の記述を行います。SIFTは画像の照明の変化や回転、スケール変化などに対して不変な特徴量を記述することができます。その分処理コストがかなり高いそうです。多分シフトって読むと思います。 SURFSpeed-Up Robust Featuresの頭文字を取ってSURFです。SURFは処理コストが高かったSIFTの改良版で、精度はSIFTに劣りますが高速にマッチングすることが可能です。SIFTでは特徴点を検出する方法として、DoG画像生成や勾配ヒストグラム生成などのコストの高い計算をしていましたが、SURFは積分画像を利用することにより約10倍の高速化しています。多分サーフって読むと思います。 HOGHistograms of Oriented Gradientsの頭文字を取ってHOGです。HOGは画像を細かいグリッドに分割して、1つ1つのセルごとに方向つき輝度勾配のヒストグラムを連結したものです。メリットとしては、勾配情報をもとにしているため、異なるサイズの画像を対象としても同じサイズにリサイズすることで比較することが可能です。多分ホグって読むと思います。 回帰普通の日本語ですが、よく出てくるので正確に理解しておきたいと思い調べました。 回帰（かいき）とは一般にはもとの位置または状態に戻ること、あるいはそれを繰り返すこと。 wiki引用 この回帰がつく用語としてよくロジスティック回帰分析という言葉を見かけますね。 ロジスティック回帰分析これはよく統計学やマーケティング関連の文脈で出てくる言葉で、YesかNoの二択のどちらかになるかを分析するための分析方法です。もっと言えば0か1、TrueかFalseのように2値をとる場合に有効です。線形回帰分析は量的変数を予測しますが、ロジスティック回帰分析は発生確率を予測する手法ということです。 SVMSupport Vector Machineの頭文字を取ってSVM(サポートベクターマシン)です。 サポートベクターマシン（英: support vector machine, SVM）は、教師あり学習を用いるパターン認識モデルの一つである。分類や回帰へ適用できる。 wiki引用 KNNk-nearest neighbor algorithmの頭文字を取ってKNNです。日本語ではk近傍法(ケイきんぼうほう)というようです。某姉貴ではない。 基づいた分類の手法であり、パターン認識でよく使われる。最近傍探索問題の一つ。k近傍法は、インスタンスに基づく学習の一種であり、怠惰学習 (lazy learning) の一種である。その関数は局所的な近似に過ぎず、全ての計算は分類時まで後回しにされる。また、回帰分析にも使われる。 wiki引用 ソフトマックス関数ソフトマックス関数は活性化関数の一種で、分類問題解く場合に、出力層で用いられる関数です。一般的に分類問題を解く場合はこのソフトマックス関数が用いられるようです。 教師データ機械学習を行う際の訓練用のデータのことです。単に訓練データという時もあるようです。まんまですね。一応調べたので書きました。 損失関数機械学習のモデルがどれだけ性能が悪いかを表す関数です。現在、教師データとどれだけ適合していないかをこの関数を通して判断することができます。有名なものに2乗和誤差や交差エントロピー誤差などがあります。 まだまだ調べないといけない用語がたくさんありますが、調べごとばかりしていると奥さんに怒られるので今回はこの辺で。終わり。","categories":[{"name":"ディープラーニング","slug":"ディープラーニング","permalink":"http://devlog.site/categories/ディープラーニング/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"ディープラーニング","slug":"ディープラーニング","permalink":"http://devlog.site/tags/ディープラーニング/"}]},{"title":"Glideを使ってみた","slug":"go4","date":"2016-12-14T15:00:00.000Z","updated":"2016-12-14T15:08:47.000Z","comments":true,"path":"Go/go4/","link":"","permalink":"http://devlog.site/Go/go4/","excerpt":"Glideについて今回はGoのパッケージマネージャーのGlideを使ってみました。","content":"Glideについて今回はGoのパッケージマネージャーのGlideを使ってみました。 はじめに環境はmacです。GlideはGo1.5以降でないと使用できません。GlideはGo1.5から追加されたVendoring機能を使用しているからです。Goの環境は依然の記事で作成しています。 Glide入れてみたGoの標準にはgo getという依存パッケージをダウンロードしてくれる便利なコマンドがあります。ただし、go getはバージョンを指定することができないという難点があります。なので今回はGlideを入れてみました。ちなみにグライド？って読むと思います。 まずはインストールです。Homebrewで一発です。 12brew updatebrew install glide インストールできたか確認してみます。 12glide -vglide version 0.12.3 無事にインストール出来てますね。これで終わりです。簡単ですね。 バージョン定義ファイルの作成インストールができたら次にバージョン定義ファイルの作成を行います。以下のコマンドで作成ができます。 1glide init コマンドが終了するとインポートしている外部ライブラリの一覧をglide.yamlファイルに書き出してくれます。 glide.yamlファイルの中身はこんな感じでそれぞれのパッケージとバージョンが記載されています。 1234567package: .import:- package: github.com/cpuguy83/go-md2man version: ^1.0.6 subpackages: - md2man... パッケージを取得定義ファイルの作成ができたら、定義に従ってパッケージを更新します。これでバージョンが固定されます。 1glide install 実行後はvendorディレクトリが作成され、依存パッケージがダウンロード・展開されます。また、glide.lockというファイルも作られ、このファイルによってバージョンが固定されます。 パッケージの追加パッケージの追加にはgo getの代わりに以下のコマンドを使用します。 1glide get github.com/xxx/xxxx このコマンドを使用すると自動的にglide.yamlの更新やvendorディレクトリへの展開を行ってくれます。 パッケージの更新パッケージにパッチが当たってバグの修正などのアップデートが行われた場合に、パッケージを更新したいことがあるかと思います。その場合には以下のコマンドを叩くだけでアップデートが行えます。 1glide up このコマンドはglide.yamlにおいてバージョンが指定されていないパッケージのみ、最新のバージョンにアップデートしてくれます。glide.yamlにバージョンを指定しているパッケージは特にアップデートは行いません。 その他リスト形式で依存パッケージを表示してくれる便利コマンドやツリー形式に表示してくれるものあります。 1glide list 1glide tree 終わり。","categories":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/tags/Go/"},{"name":"Glide","slug":"Glide","permalink":"http://devlog.site/tags/Glide/"}]},{"title":"Revelフレームワークpart2","slug":"go3","date":"2016-12-13T15:00:00.000Z","updated":"2016-12-13T16:03:29.000Z","comments":true,"path":"Go/go3/","link":"","permalink":"http://devlog.site/Go/go3/","excerpt":"Revel入門折角Revelフレームワークでサンプルアプリを作ったので、もう少し勉強してみようと思います。フレームワークのインストールは前回の記事を参照して下さい。","content":"Revel入門折角Revelフレームワークでサンプルアプリを作ったので、もう少し勉強してみようと思います。フレームワークのインストールは前回の記事を参照して下さい。 テンプレートをいじってみるまずは見た目を少しいじってみたいと思います。 1myapp/app/views/App/Index.html viewのファイルの拡張子は.htmlなんですね。中身を見てみると 123456789101112131415161718192021&#123;&#123;set . \"title\" \"Home\"&#125;&#125;&#123;&#123;template \"header.html\" .&#125;&#125;&lt;header class=\"jumbotron\" style=\"background-color:#A9F16C\"&gt; &lt;div class=\"container\"&gt; &lt;div class=\"row\"&gt; &lt;h1&gt;It works!&lt;/h1&gt; &lt;p&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/header&gt;&lt;div class=\"container\"&gt; &lt;div class=\"row\"&gt; &lt;div class=\"span6\"&gt; &#123;&#123;template \"flash.html\" .&#125;&#125; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&#123;&#123;template \"footer.html\" .&#125;&#125; こんな感じになってるんですね。テンプレートエンジンはちょっとクセがありそうに見えるけどどうなんでしょう。中身を見てみましょう。 テンプレート関数Index.htmlの1行目に 1&#123;&#123;set . &quot;title&quot; &quot;Home&quot;&#125;&#125; とありますが、これはRevelのテンプレート関数であるset関数を呼び出す構文になります。これはtitleに”Home”という文字列をアサインするという意味です。ただtitleはIndex.html内には見当たりません。どこにあるかというと別のファイルの 1myapp/app/views/header.html になります。header.htmlを見てみると\\{\\{.title\\}\\}と埋め込まれる箇所が用意されているのがわかりますね。 1&lt;title&gt;&#123;&#123;.title&#125;&#125;&lt;/title&gt; この\\{\\{.title\\}\\}にset関数で指定した”Home”がアサインされます。ブラウザから確認するとタイトルがHomeになっていることが分かるかと思います。 2行目は別ファイルを読み込む処理になります。 1&#123;&#123;template &quot;header.html&quot; .&#125;&#125; こちらもテンプレート関数であるtemplate関数を呼び出す構文です。ここではheader.htmlを読み込んでいますね。こうすることでいろんなページで共通のヘッダーやフッターを1つにまとめて読み込むことができますね。 このようにテンプレート側からも関数を呼び出すことで色々な処理が書けそうです。どんな関数があるかはこちらの公式から確認することができます。 Viewに変数をアサインしてみるテンプレート内からのアサインはset関数できますが、コントローラーからのアサインはどのようにやるのか調べてみました。修正するファイルはTOPページのコントローラである 1myapp/app/controllers/app.go こちらのファイルになります。app.goファイルを以下のように編集しました。 1234func (c App) Index() revel.Result &#123; hello := \"Hello\" return c.Render(hello)&#125; これでコントローラ内からViewにhelloという変数がアサインできました。次にView側でそれを表示してみたいと思います。Index.htmlに\\{\\{.hello\\}\\}を追加します。 1&lt;h1&gt;&#123;&#123;.hello&#125;&#125;&lt;/h1&gt; ブラウザで確認するときちんとHelloと表示されていることがわかりますね。 終わり。","categories":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/tags/Go/"},{"name":"Revel","slug":"Revel","permalink":"http://devlog.site/tags/Revel/"},{"name":"プログラミング","slug":"プログラミング","permalink":"http://devlog.site/tags/プログラミング/"}]},{"title":"Revelフレームワークpart1","slug":"go2","date":"2016-12-12T15:00:00.000Z","updated":"2016-12-13T16:03:36.000Z","comments":true,"path":"Go/go2/","link":"","permalink":"http://devlog.site/Go/go2/","excerpt":"Revelフレームワークを試してみたRevelはgoのフルスタックのWebフレームワークです。Dockerと一緒にこのRevelでできたWebアプリも引き継ぐことになったので今回は勉強の為、ローカルでチュートリアルを試してみようと思います。","content":"Revelフレームワークを試してみたRevelはgoのフルスタックのWebフレームワークです。Dockerと一緒にこのRevelでできたWebアプリも引き継ぐことになったので今回は勉強の為、ローカルでチュートリアルを試してみようと思います。 はじめにgoのインストールはすでに終わっています。前回、gvmでインストールしてますので、気になる方は見てみてください。 インストールgo getによりリポジトリからrevelをインストールします。 1go get github.com/robfig/revel 次にコマンドラインツールをインストールします。 1go get github.com/revel/cmd/revel インストールできているか確認します。 1234567$ revel version ~~ revel! http://revel.github.io~Version(s): Revel v0.13.1 (2016-06-06) go1.7 darwin/amd64 バージョンの確認ができましたね。これでインストールは終わりです。 RevelコマンドRevelには6つのコマンドがあります。1つ1つ見ていきましょう。 1revel new アプリケーションのスケルトンを作成します。 1revel run テスト用にアプリケーションを起動します。 1revel build アプリケーションをビルドします。 1revel package アプリケーションをデプロイ用パッケージを作成します。 1revel clean 一時ファイルを削除します。 1revel test テストを実行します。 サンプルアプリを作ってみるrevelがインストールできたら早速アプリを作ってみたいと思います。revelコマンドから新しくサンプルアプリを作成します。 1revel new myapp $GOPATH/src/myapp にアプリケーションのスケルトンが作成されます。myapp以下のディレクトリ構造はこんな感じです。 123456789101112131415161718192021222324252627282930313233343536373839|--.gitignore|--README.md|--app| |--controllers| | |--app.go| |--init.go| |--routes| | |--routes.go| |--tmp| | |--main.go| |--views| | |--App| | | |--Index.html| | |--debug.html| | |--errors| | | |--404.html| | | |--500.html| | |--flash.html| | |--footer.html| | |--header.html|--conf| |--app.conf| |--routes|--messages| |--sample.en|--public| |--css| | |--bootstrap-3.3.6.min.css| |--fonts| | |--glyphicons-halflings-regular.ttf| | |--glyphicons-halflings-regular.woff| | |--glyphicons-halflings-regular.woff2| |--img| | |--favicon.png| |--js| | |--bootstrap-3.3.6.min.js| | |--jquery-2.2.4.min.js|--tests| |--apptest.go 実際にアプリケーションを起動してみましょう。 1revel run myapp revelのビルトインサーバーが立ち上がるのでlocalhost:9000にアクセスしてみましょう。アプリの画面が表示されると思います。 終わり。","categories":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/tags/Go/"},{"name":"Revel","slug":"Revel","permalink":"http://devlog.site/tags/Revel/"},{"name":"プログラミング","slug":"プログラミング","permalink":"http://devlog.site/tags/プログラミング/"}]},{"title":"Go言語インストール","slug":"go1","date":"2016-12-11T15:00:00.000Z","updated":"2016-12-12T14:17:45.000Z","comments":true,"path":"Go/go1/","link":"","permalink":"http://devlog.site/Go/go1/","excerpt":"Go入門仕事でGoを使う必要があったので、今更ながらGoを勉強してみたいと思います。","content":"Go入門仕事でGoを使う必要があったので、今更ながらGoを勉強してみたいと思います。 はじめに環境はMacです。自分の為の備忘録ですので悪しからず。 gvmインストールgvmでGoの管理をしたいと思います。gvmのインストールには以下を実行します。 1bash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) インストールが終わったらコンソールの指示に従って以下を実行します。 1source ~/.gvm/scripts/gvm ちゃんと動くか確認します。 12$ gvm versionGo Version Manager v1.0.22 installed at /Users/hoge/.gvm 大丈夫そうですね。 Goのインストールインストールできるバージョンの一覧を確認します。 12345678gvm listall go1 go1.0.1 go1.0.2 go1.0.3 go1.1 go1.1.1 ... 今回は1.7.4をインストールしてみたいと思います。 1gvm install go1.7.4 と、途中でエラーが出てしまいました。 123456$ gvm install go1.7.4Downloading Go source...Installing go1.7.4... * Compiling...ERROR: Failed to compile. Check the logs at /Users/hoge/.gvm/logs/go-go1.7.4-compile.logERROR: Failed to use installed version エラーログの中身を確認するとgoの1.4がないって怒られている様子。なので先に1.4.3をインストールしてみます。 1gvm install go1.4.3 go1.4.3は素直にインストールができました。 1gvm use go1.4.3 バージョンを1.4.3に切り替えて再度1.7.4をインストールしてみるとソースのダウンロードに結構時間がかかりましたが、無事にインストールが終わりました。 12345$ gvm list=&gt; go1.4.3 go1.7.4 system ちゃんとインストールされていますね。このままだと1.4.3になっているので1.7.3に切り替えます。 1gvm use go1.7.4 --default ちゃんと切り替わっていますね。 12345$ gvm list go1.4.3=&gt; go1.7.4 system 無事Goのインストールができました。この後、少しGoで遊んでみました。 Goのimportの書き方Goを書き始めてまず気になったimportの書き方についてです。Githubからパッケージをそのままインポートできたりしてすごく便利なんですが、結構色々な書き方があるみたいなので調べてみました。 ファイルからの相対パスで指定1import &quot;./model&quot; GOPATHからの絶対パスで指定1import &quot;shorturl/model&quot; グループ化して複数指定1234import ( &quot;fmt&quot; &quot;string&quot;) ドットをパッケージの前に書く1234import ( . &quot;fmt&quot; &quot;string&quot;) fmt.Println(“hello world”)と書くところをドットをつけるとPrintln(“hello world”)とパッケージ名を省略することができます。 エイリアスを付ける123import ( f &quot;fmt&quot;) パッケージ名の前にエイリアスを指定することで、fmt.Println(“hello world”)と書くところf.Println(“hello world”)と書くことができます。パッケージ名が同じ他のパッケージを使用したい場合などにエイリアスを指定して別名を付けてあげる場合などに使用します。 アンダースコアをパッケージの前に書く1234import ( &quot;database&quot; _ &quot;github.com/go-sql-driver/mysql&quot;) 対象のパッケージのinit関数だけ実行されます。これはブランク識別子というもので、importした対象のパッケージと依存関係のある他のパッケージをimportするときに指定します。 Goについても今後少しづつ勉強していこうと思います。終わり。","categories":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"http://devlog.site/tags/Go/"},{"name":"プログラミング","slug":"プログラミング","permalink":"http://devlog.site/tags/プログラミング/"}]},{"title":"ttyとptsについて","slug":"tty","date":"2016-12-10T15:00:00.000Z","updated":"2016-12-11T12:05:07.000Z","comments":true,"path":"コマンド/tty/","link":"","permalink":"http://devlog.site/コマンド/tty/","excerpt":"ttyとptsがわからなかったので調べてみたttyとptsについて良くわかってなかったので調べてみました。自分メモです。","content":"ttyとptsがわからなかったので調べてみたttyとptsについて良くわかってなかったので調べてみました。自分メモです。 screenコマンドttyとptsの前にscreenコマンドについてです。 そもそもttyとptsが何なのか調べたのは、このscreenコマンドでDocker for Mac のxhive環境へのログインする必要があり、その前提知識としてtty、ptsどんなものなのか知る必要があったからです。 で、まずscreenコマンドはというと、screenコマンドは１つのターミナル上で、仮想的に複数の端末を同時にオープンして作業できるようにするコマンドです。仮想端末が開かれた状態を保ったままターミナルをログアウトできたり、後から再度ログインして、screenを呼び出すことで仮想端末の状態に復帰することができます。例えば処理にすごく時間のかかる作業がある場合に仮想端末上でそれを行わせてから元のターミナルで他の作業をするなどに使えるようです。 結構便利なコマンドですね。全然知りませんでした…このscreenコマンドでDockerのttyを指定できるようです。 ttyコマンドそしてそもそもttyとかptsってなんぞや？ってとこですが、まずttyコマンドというコマンドがあります。ttyコマンドは標準入出力となっている端末デバイスの名前を表示するコマンドです。テレタイプライターでttyだそうです。ttyコマンドはあまり聞きませんが、よくpsコマンドでプロセス確認する時にttyって見かけますよね。こんな感じで。 12345$ ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 21944 0.0 0.0 4064 436 tty1 Ss+ Aug23 0:00 /sbin/mingetty /dev/tty1root 23504 0.0 0.0 4080 500 ttyS0 Ss+ Aug23 0:00 /sbin/agetty /dev/ttyS0 115200 vt100-nav... tty自体はデバイスファイルとしても存在していて、/dev/ttyにあります。/dev/ttyは物理的な標準出力の端末なので、こんなこともできます。 12$ echo &quot;Hello world&quot; &gt; /dev/ttyHello world /dev/ttyへ文字をリダイレクトするとスクリーンにその文字が出力されます。標準出力に文字を送ったので当たり前といば当たり前ですね。ということでttyは物理できな標準出力ってことですね。 ちなみにptsはsshなどで繋いだ場合の仮想端末のことで、sshで繋いだサーバ上でscreenコマンドで複数の仮想端末を立ち上げるとこんな風になります。 12345$ tty/dev/pts/0$ screen$ tty/dev/pts/1 screenコマンドで別の仮想端末が立ち上がったことがttyコマンドで確認できますね。Dockerで起動中のコンテナにアタッチした時にscreenコマンドが使えると便利そうですね。 終わり。","categories":[{"name":"コマンド","slug":"コマンド","permalink":"http://devlog.site/categories/コマンド/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://devlog.site/tags/Docker/"},{"name":"tty","slug":"tty","permalink":"http://devlog.site/tags/tty/"},{"name":"pts","slug":"pts","permalink":"http://devlog.site/tags/pts/"}]},{"title":"ニューラルネットワーク入門","slug":"neural-network1","date":"2016-12-08T15:00:00.000Z","updated":"2016-12-09T13:04:40.000Z","comments":true,"path":"ディープラーニング/neural-network1/","link":"","permalink":"http://devlog.site/ディープラーニング/neural-network1/","excerpt":"ニューラルネットワークの実装今回も「ゼロから作るディープラーニング」をもとにニューラルネットワークの実装をPythonでお行いたいと思います。","content":"ニューラルネットワークの実装今回も「ゼロから作るディープラーニング」をもとにニューラルネットワークの実装をPythonでお行いたいと思います。 入力2出力3のニューラルネットワークNumPyの行列計算を使用して、入力が2つ、出力が3つのニューラルネットワークを実装してみます。ここではバイアスと活性化関数は一旦置いておきます。Xは入力、Wは重み、Yは出力を示しています。 12345678910111213In [1]: import numpy as npIn [2]: X = np.array([1,2])In [3]: X.shapeOut[3]: (2,)In [4]: W = np.array([[1,3,5],[2,4,6]])In [5]: print(W)[[1 3 5] [2 4 6]]In [6]: W.shapeOut[6]: (2, 3)In [7]: Y = np.dot(X, W)In [8]: print(Y)[ 5 11 17] Xの入力は2つの要素を持つ1次元配列で、重みのWが2x3の配列となり、出力Yが3つの要素を持つ1次元配列になっていることがわかります。これは入力が2つで出力が3つあるニューラルネットワークになります。 3層構造のニューラルネットワーク次にバイアスと活性化関数を考慮した3層構造のニューラルネットワークを実装してみます。Bをバイアス、A1は行列の内積を示しています。 1234567891011In [1]: import numpy as npIn [2]: X = np.array([1.0, 0.5])In [3]: W1 = np.array([[0.1, 0.3, 0.5],[0.2, 0.4, 0.6]])In [4]: B1 = np.array([0.1, 0.2, 0.3])In [5]: X.shapeOut[5]: (2,)In [6]: W1.shapeOut[6]: (2, 3)In [7]: B1.shapeOut[7]: (3,)In [8]: A1 = np.dot(X, W1) + B1 ここまでで0層目から1層目への入力ができました。次にノード内で行われる活性化関数の実装を行いたいと思います。本に従ってシグモイド関数を使用します。Z1は1層目の出力を示しています。 12345678In [9]: def sigmoid(x): ...: return 1 / (1 + np.exp(-x)) ...: In [10]: Z1 = sigmoid(A1)In [11]: print(A1)[ 0.3 0.7 1.1]In [12]: print(Z1)[ 0.57444252 0.66818777 0.75026011] 次に1層目から2層目への入力を行います。W2が1層目から2層目への重みで、B2がバイアス、Z1が入力、A2が内積を示しています。 12345678910In [13]: W2 = np.array([[0.1, 0.4],[0.2, 0.5],[0.3, 0.6]])In [14]: B2 = np.array([0.1, 0.2])In [15]: Z1.shapeOut[15]: (3,)In [16]: W2.shapeOut[16]: (3, 2)In [17]: B2.shapeOut[17]: (2,)In [18]: A2 = np.dot(Z1, W2) + B2In [19]: Z2 = sigmoid(A2) 0層目から1層目に行ったこととほぼ同じですね。最後に2層目から3層目の実装です。予想ができると思いますが、3層目の計算も今までの0層目から1層目、1層目から2層目と同じようなイメージです。 1234567In [20]: def identity_function(x): ....: return x ....: In [21]: W3 = np.array([[0.1, 0.3],[0.2, 0.4]])In [22]: B3 = np.array([0.1, 0.2])In [23]: A3 = np.dot(Z2, W3) + B3In [24]: Y = identity_function(A3) 2層目の実装と少し違うところがあると思います。それはidentity_function()を定義して活性化関数として最後のノードに使用しているところです。恒等関数と言って入力をそのまま出力する関数です。最後のノードでなぜ恒等関数を使用するかというと、問題の性質に応じてこの関数を変えて欲しいからです。今回は適当なデータでサンプルを実装した為、恒等関数を使用しただけのことです。 終わり。","categories":[{"name":"ディープラーニング","slug":"ディープラーニング","permalink":"http://devlog.site/categories/ディープラーニング/"}],"tags":[{"name":"ディープラーニング","slug":"ディープラーニング","permalink":"http://devlog.site/tags/ディープラーニング/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"}]},{"title":"Docker入門","slug":"docker2","date":"2016-12-07T15:00:00.000Z","updated":"2016-12-07T15:25:35.000Z","comments":true,"path":"docker/docker2/","link":"","permalink":"http://devlog.site/docker/docker2/","excerpt":"Dockerを使ってみた業務でDocker環境を引き継いだもののDcokerはさっぱりわからないので、まずは使える環境をローカルにも作ってみました。","content":"Dockerを使ってみた業務でDocker環境を引き継いだもののDcokerはさっぱりわからないので、まずは使える環境をローカルにも作ってみました。 はじめにHomebrewでもインストールできるみたいですが、今回はDocker for Macを公式サイトの手順に従ってインストールして行いたいと思います。 インストール公式サイトからインストーラをダウンロードします。インストーラを起動させた際にDocker Toolboxを使用していた場合、設定などをコピーしますかと聞かれます。自分はDocker Toolboxをちょろっと試したことがあったのでダイアログが出ましたが、コピーする必要はないのでNoで進めました。 起動インストール後Docker.appをアプリケーションから起動します。起動の際にVirtualBoxのバージョンが古いとアップグレードしてください。と注意されます。もし注意されたらVirtualBoxのバージョンを上げましょう。起動するとメニューバーにDockerのアイコンが表示されます。 メニューバーのアイコンからはPreferenceの設定などができます。 試してみる無事に起動できたみたいなのでターミナルからコマンドを叩いてみたいと思います。 12345678910111213141516⋊&gt; ~ docker version 14:20:49Client: Version: 1.12.3 API version: 1.24 Go version: go1.6.3 Git commit: 6b644ec Built: Wed Oct 26 23:26:11 2016 OS/Arch: darwin/amd64Server: Version: 1.12.3 API version: 1.24 Go version: go1.6.3 Git commit: 6b644ec Built: Wed Oct 26 23:26:11 2016 OS/Arch: linux/amd64 これでDockerが使えるようになりましたね。 Dockerイメージをsave/loadしてみるDocekrイメージを別環境へ移動するやり方は調べるといくつかあるみたいですが、元の環境でsaveしてからインポートしたい環境でloadするやり方を試してみたいと思います。 まずDockerが動いてる環境でsaveをしてtar.gzにします。imagesで一覧を確認します。 123$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEmysql latest e571f0e3f4a6 9 months ago 385.5 MB 次にsaveでイメージをtar.gzします。 1$ docker save e571f0e3f4a6 &gt; image.tar 移動したい環境へ作成したtarをscpなどで移動して、loadを実行します。 1$ docker load &lt; image.tar loadが終わったらimagesで確認してみましょう。 123$ docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEmysql latest e571f0e3f4a6 9 months ago 385.5 MB ちゃんとimagesの一覧に出てきましたね。これで移動ができました。ちなみにexport/importというコマンドもあり、save/loadとの違いは、exportはDockerイメージのファイルシステムをまるっとtarで固めただけで、saveは親子関係やメタデータも含めて固めてくれるようです。 mysqlコンテナを立ち上げてみる次にmysqlコンテナを立ち上げてみたいと思います。 1docker run --name mysqld -e MYSQL_DATABASE= -e MYSQL_USER=root -e MYSQL_PASSWORD=secret -e MYSQL_ROOT_PASSWORD=verysecret -d mysql mysqlの環境変数を-eで指定できるのでユーザやデータベースを指定して起動することができます。ローカルからmysqlへ繋ぎにいけるか確認してみます。 1234567891011121314$ docker exec -it mysqld mysql -u user -pパスワードWelcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 6Server version: 5.7.15 MySQL Community Server (GPL)Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.mysql&gt; 無事に接続できましたね。ちなみにローカルのmysqlコマンドを使用してもコンテナのIPを指定すれば繋ぎに行くこともできます。 1mysql -hコンテナIP -u user -pパスワード コンテナのIPアドレスは以下のコマンドで確認できます。 1docker inspect --format &apos;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&apos; コンテナIDまたはコンテナ名 データの永続化最後に気をつけないといけないのがmysqlに保存しているデータについてです。コンテナ内にデータを保存する場合、コンテナ作成時に-vオプションを指定する必要があります。 1docker run --name mysqld -v /var/lib/mysql -d mysql こんな感じで、-vの後に保存先のパスを指定してあげます。(-eオプションは省略してます。)ただし、mysqlコンテナにデータ自体も保存してしまうとDockerの長所であるポータビリティが失われてしまいます。そこでデータのみを格納するコンテナを別に作成することで、データ自体のポータビリティを保ちます。適当にストレージとなるコンテナを作成します。 1docker run -it -v /var/lib/mysql --name strage image 作成したストレージコンテナを指定してmysqlコンテナを作成しなおします。 1docker run --volumes-from strage --name mysqld -d mysql これでデータを格納するコンテナとmysqlのコンテナを切り離すことができました。こうしておけばデータだけを移したいときに便利ですね。 今後は趣味で色々と試してみたいと思います。","categories":[{"name":"Docker","slug":"docker","permalink":"http://devlog.site/categories/docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://devlog.site/tags/Docker/"},{"name":"mysql","slug":"mysql","permalink":"http://devlog.site/tags/mysql/"}]},{"title":"行列の計算","slug":"numpy2","date":"2016-12-06T15:00:00.000Z","updated":"2016-12-06T23:30:02.000Z","comments":true,"path":"python/numpy2/","link":"","permalink":"http://devlog.site/python/numpy2/","excerpt":"多次元配列の計算について引き続き「ゼロから作るディープラーニング」を読んでます。多次元配列の計算について、忘れないようにメモしておきます。","content":"多次元配列の計算について引き続き「ゼロから作るディープラーニング」を読んでます。多次元配列の計算について、忘れないようにメモしておきます。 はじめに環境などはこちらを参考にして下さい。浅〜いメモなので悪しからず。 NumPyで多次元配列を扱うNumPyで多次元の配列について諸々試してみました。まずは1次元配列から 12345678910In [1]: import numpy as npIn [2]: A = np.array([1,2,3,4])In [3]: print(A)[1 2 3 4]In [4]: np.ndim(A)Out[4]: 1In [5]: A.shapeOut[5]: (4,)In [6]: A.shape[0]Out[6]: 4 np.ndim()関数で対象の配列が何次元の配列かがわかります。A.shapeで配列の形状が取得できます。戻り値はどうやらタプルで返ってくるようですね。A.shape[0]とインデックスを指定してあげると対象の次元の形状が取得できるんですね。 次に2次元配列です。 12345678910In [1]: import numpy as npIn [2]: B = np.array([[1,2],[3,4],[5,6]])In [3]: print(B)[[1 2] [3 4] [5 6]]In [4]: np.ndim(B)Out[4]: 2In [5]: B.shapeOut[5]: (3, 2) np.ndim()が2を返していますね。それとB.shapeが(3,2)になっています。これで3x2の配列であることがわかりますね。3x2の配列とは一つ目の次元に3つ要素があり次の次元に2つの要素があるってことですね。上の式のB = np.array([[1,2],[3,4],[5,6]])をわかりやすく書くと 1234B = [X, Y, Z]X = [1, 2]Y = [3, 4]Z = [5, 6] こんな感じになります。まずBは3つの要素(X, Y, Z)を持っていて、X、Y、Zが[1, 2]、[3, 4]、 [5, 6]の2つの要素が入った配列になっていますので3x2の配列になるんですね。 またこんな風にも表すことができます。 $$\\begin{bmatrix}1 &amp; 2 \\\\3 &amp; 4 \\\\5 &amp; 6\\end{bmatrix}$$ このように表記した場合の横方向の並びを行、縦方向の並びを列を呼びます。ここでは1、2が1つの行、1、3、5が1つの列といった具合です。 行列の内積次に行列の内積についてです。行列の内積の定義は1a・b = |a||b|cosθ で定義されます。θは2つのベクトルの始点をそろえたときにできる「なす角」のことです。内積には幾何的な意味と代数的な意味の二つの定義があり、どちらかというと物理の分野で広く聞く言葉ですね。 定義を見てもさっぱりだと思うので簡単に言うと「ベクトルaの長さ」と、「ベクトルbをベクトルa上に射影したものの長さ」の積で求められるものということですね。イメージするのが難しいと思うので具体的な計算方法を見てみましょう。Pythonで行列の内積を計算する実装です。 1234567In [1]: import numpy as npIn [2]: A = np.array([[1,2],[3,4]])In [3]: B = np.array([[5,6],[7,8]])In [4]: np.dot(A, B)Out[4]: array([[19, 22], [43, 50]]) ここでは $$\\begin{bmatrix}1 &amp; 2 \\\\3 &amp; 4\\end{bmatrix}$$ と $$\\begin{bmatrix}5 &amp; 6 \\\\7 &amp; 8\\end{bmatrix}$$ という二つの行列の内積の計算を行っています。内積の計算にはnp.dot()関数を使用します。 行列の内積の計算は左側の行列の行と右側の配列の列をそれぞれの要素の積とその和で求めることができます。例えば1行目の1列目は1 * 5 + 2 * 7で答えが19となります。 計算自体は簡単ですね。内積は概念がまだまだ理解できていないので今後も詳しく調べていきたいです。ということで終わり。","categories":[{"name":"python","slug":"python","permalink":"http://devlog.site/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"NumPy","slug":"NumPy","permalink":"http://devlog.site/tags/NumPy/"},{"name":"数学","slug":"数学","permalink":"http://devlog.site/tags/数学/"}]},{"title":"機械学習用語","slug":"vocabulary1","date":"2016-12-05T15:00:00.000Z","updated":"2016-12-06T00:22:23.000Z","comments":true,"path":"machine-learning/vocabulary1/","link":"","permalink":"http://devlog.site/machine-learning/vocabulary1/","excerpt":"わからない用語を調べたディープラーニングを勉強しているとわからない用語がまぁ〜出てきます。今回はわからない用語を調べたのでそれをまとめました。毎度のことながら自分用のメモです。浅くしか調べてません。すいません。 活性化関数入力信号の総和を出力信号に変換する関数。伝達関数ともいう。","content":"わからない用語を調べたディープラーニングを勉強しているとわからない用語がまぁ〜出てきます。今回はわからない用語を調べたのでそれをまとめました。毎度のことながら自分用のメモです。浅くしか調べてません。すいません。 活性化関数入力信号の総和を出力信号に変換する関数。伝達関数ともいう。 活性化関数としてはパーセプトロンが登場した頃の1950年代はステップ関数が多く、1986年のバックプロパゲーションの発表以降はシグモイド関数が最も一般的だったが、現在は ReLU（ランプ関数）の方が良いと言われる。活性化関数は単調増加関数が使われる事が多いが、必ずしもそうしなければいけないという物でもなく動径基底関数なども使われる。 wiki引用 ステップ関数やシグモイド関数のこと。ディープラーニングでは結構よく出てくる用語の一つですね。 ネイピア数数学の記号eで表す自然対数の底のことです。欧米ではオイラー数とも呼ばれるようです。以下の式で表すことができ、 $$e = \\lim_{n \\to \\infty} (1 + \\frac{1}{\\ n})^n$$ 数値自体はe = 2.71828 18284 59045 23536 02874 71352 …となります。この定数は、指数関数や対数関数の微分でよく使われています。e^xを微分するとe^xとなり、loge e xを微分すると1/xとなる特徴があります。 まぁよくわからないですが、とりあえず自然対数の底でアルファベットのeと、この程度でまずはいいと思います。今後もっと詳しく調べてみたいと思います。完全に数学です… ステップ関数 階段関数（かいだんかんすう、英: step functionまたは英: staircase function）とは、おおまかに言って、グラフが階段状になる実関数のことである。より正確には、区間上の指示関数が有限個あって、それらの線型結合で表される関数である。有限個のみの区分を持った、区分的に定数関数である関数とも表現できる。 wiki引用 wikiを読んでもよくわからんですね。ちょっと難しいですが、用はグラフが階段状になっていたら、それはステップ関数だってことですね。で、活性化関数として昔は使われていたが、出力の値が0か1と極端だったので今は使われていないってことを覚えておけば良さそうです。 シグモイド関数活性化関数をステップ関数とすると変化が急すぎるため、ステップ関数の変化を少し滑らかにした関数。それがシグモイド関数です。以下のような式で表すことができます。 $${\\sigma_a}(x) = \\frac{1}{\\ 1 + e^{-ax}}$$ この時aの値を大きくすればするほどステップ関数に似たような関数になりますが、急激な変化ではなく少し滑らかな変化になります。これも昔は使われていたが最近はあまり使われなくなっている活性化関数の一つと覚えておけばいいかもですね。 線形関数いわゆる一次関数のような直線で表せる関数のことで、出力が入力の定数倍になるような関数です。また線形性がある関数とも言えます。線形性とは、 線型性（せんけいせい、英語: linearity）あるいは線型、線形、線状、リニア（せんけい、英語: linear、ラテン語: linearis）とは、直線そのもの、または直線のようにまっすぐな図形やそれに似た性質をもつ対象および、そのような性質を保つ変換などを指して用いられている術語である。 wiki引用 簡単に直線が引ける関数ってことですね。 非線形関数線形関数とは逆で読んで字のごとく線形ではない、線形では表せない関数ってことですね。もっと言うと直線で引けない関数ってことです。ステップ関数やシグモイド関数も非線形関数の一つです。 これは分かりやすいですね。線形、非線形って言葉も結構よく出てきますので覚えておきましょう。 ReLU（ランプ）関数ReLUでランプと読むようですね。変わってますねw ランプ関数（英: ramp function）とは、一変数の実関数であり、独立変数とその絶対値の平均として容易に求められる。区分線形関数。この関数は工学において（DSPの理論など）応用を持つ。”ramp function”の名は、グラフの形状が傾斜路（英: ramp）に似ていることに由来する。 wiki引用 この関数もwikiを読んでもちょっとよくわからないですね。簡単に説明すると、入力が0を超えている場合はその値をそのまま出力して、0以下なら0を出力するといった関数です。 他にもたくさんありますが、一旦ここで終わり。","categories":[{"name":"機械学習","slug":"machine-learning","permalink":"http://devlog.site/categories/machine-learning/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"数学","slug":"数学","permalink":"http://devlog.site/tags/数学/"}]},{"title":"パーセプトロンについて","slug":"perceptron","date":"2016-12-04T15:00:00.000Z","updated":"2016-12-05T13:23:47.000Z","comments":true,"path":"ディープラーニング/perceptron/","link":"","permalink":"http://devlog.site/ディープラーニング/perceptron/","excerpt":"パーセプトロンについて今読んでる「ゼロから作るディープラーニング」に出てくるパーセプトロンについて調べてみました。 パーセプトロンとは？パーセプトロンとはディープラーニングの起源にとなるアルゴリズムで、ローゼンブラットさんというアメリカの研究者によって1957年に考案されたものです。","content":"パーセプトロンについて今読んでる「ゼロから作るディープラーニング」に出てくるパーセプトロンについて調べてみました。 パーセプトロンとは？パーセプトロンとはディープラーニングの起源にとなるアルゴリズムで、ローゼンブラットさんというアメリカの研究者によって1957年に考案されたものです。 パーセプトロンは複数の入力を受け、一つの出力を行うものです。複数の入力から出力がどのような結果になるかを計算するもののことですね。 例えば入力がx1、x2と二つあった場合、yを出力とします。そしてこの入力のx1とx2にはそれぞれ重み付けがあり、その重みをw1、w2とします。この重みはそれぞれの入力と乗算され、w1x1、w2x2と計算されます。この時yの値は以下のような計算式になります。 12y = (w1x1 + w2x2 &lt;= θ) = 0y = (w1x1 + w2x2 &gt; θ) = 1 この式のθは閾値であり、ある一定値を示しています。w1x1 + w2x2の結果がこの一定値を超えると出力は1となり、超えないと0になります。この時、閾値を超えることをニューロンが発火するなんて言ったりもします。 これは重みづけによってそれぞれの入力の重要性をコントロールしており、重みによって閾値を超えるかどうかが変わってくるってことですね。 ANDゲート本の中でも紹介されているANDゲートの例ですが、分かりやすかったので自分なりにまとめてみました。 ANDゲートとは論理回路で使われる2つの入力から1つの出力を得る論理積のゲートです。下のような図を真理値表と言って入力と出力の関係を図にしたものです。 x1 x2 y 0 0 0 1 0 0 0 1 0 1 1 1 x1とx2が1の場合のみyが1になりそれ以外は0になります。これがANDゲートです。ではこのANDゲートをパーセプトロンで表すとどうなるでしょう。x1、x2、yの値はすでに決まっているので残りの重み(w1、w2)と閾値(θ)の値をこの真理値表を満たすように設定してやれば良いのです。 ANDゲートを満たす値は？実はこのANDゲートを満たす重み(w1、w2)と閾値(θ)の組み合わせは無数にあります。(w1, w2, θ) = (0.5, 0.5, 0.7)でもいいですし(w1, w2, θ) = (1.0, 1.0, 1.0)でも問題ありません。考えればもっとたくさんありますし、案外簡単に見つけられますね。 NANDゲートとORゲート次に似たような問題で、NANDゲートとORゲートについても同じように考えてみましょう。まずNANDゲートは以下のような真理値表になります。ANDゲートを反転させたイメージです。 x1 x2 y 0 0 1 1 0 1 0 1 1 1 1 0 NANDゲートも同様にパーセプトロンで表すとどうなるか考えてみましょう。NANDゲートも結構すぐに色々な答えがあることがわかると思います。例えば(w1, w2, θ) = (-0.5, -0.5, -0.8)とかですね。 次にORゲートです。ORゲートは以下のような真理値表になります。 x1 x2 y 0 0 0 1 0 1 0 1 1 1 1 1 これも考えると結構すぐにわかりますね。 まとめパーセプトロンの重みと閾値を自分で考えましたが、この重みと閾値をコンピュータに考えさせ、学習されることができれば機械学習ができてるってことになります。 また今回は本を参考に真理値表を学習データの例にしていますが、このような学習データがあればその他の分野でも重みと閾値を見つけ出すことができるはずですね。","categories":[{"name":"ディープラーニング","slug":"ディープラーニング","permalink":"http://devlog.site/categories/ディープラーニング/"}],"tags":[{"name":"ディープラーニング","slug":"ディープラーニング","permalink":"http://devlog.site/tags/ディープラーニング/"},{"name":"パーセプトロン","slug":"パーセプトロン","permalink":"http://devlog.site/tags/パーセプトロン/"},{"name":"論理回路","slug":"論理回路","permalink":"http://devlog.site/tags/論理回路/"}]},{"title":"DNSレコードについて調べてみた","slug":"dns1","date":"2016-12-03T15:00:00.000Z","updated":"2016-12-09T13:06:26.000Z","comments":true,"path":"DNS/dns1/","link":"","permalink":"http://devlog.site/DNS/dns1/","excerpt":"DNSレコードについて調べてみたDNSレコードの設定をする機会があり、今まで結構なぁなぁでやっていたのでこれを機に少し調べてみました。簡単なメモです。","content":"DNSレコードについて調べてみたDNSレコードの設定をする機会があり、今まで結構なぁなぁでやっていたのでこれを機に少し調べてみました。簡単なメモです。 DNSレコードとは？まずDNSレコードの前にDNSとは、名前解決、つまりIPアドレスとドメインをマッピングして相互変換するものです。 ではDNSレコードとは何かというと、その名前解決についての設定の記述の仕方のことです。DNSレコードには種類があり、それぞれに役割があります。例えば、このドメイン名はこのIPアドレスのことですよ。というドメイン名とIPアドレスをマッチンピングする設定をしておく場合はAレコードを指定します。 DNSレコードの種類Aレコード以外にもたくさんの種類があります。wikiを見ていただけるとわかると思いますが、まぁまぁ種類がありますね。 その中でも主に指定するレコードがこちらです。 レコード 意味 NS ドメインのDNSサーバ名を指定する A ホストのIPアドレス PTR IPアドレスに対するホスト名 CNAME ホスト名のエイリアス（別名） MX ドメインのメール・サーバ名 HINFO ホストの追加情報。ホストのハードウェア・ソフトウェア（OS）情報を記述する WKS ホストで実行されているサービス情報（Well Known Services） TXT ホストへのテキスト情報 この中でもよくCNAMEレコードは結構使う気がします。CNAMEレコードはAレコードで定義されてるドメイン名と別名を定義します。対象のドメイン名を別のドメインとしても扱えるようにすることができるってことですね。 終わり。今回はDNSレコードについて調べてみましたが、DNSについても次回以降書きたいと思います。DNS自体も毎度調べてわかったと思って満足して、しばらくすると忘れてしまうので再度復習しないとなぁと思ってます。きちんと理解するのって大変。","categories":[{"name":"DNS","slug":"DNS","permalink":"http://devlog.site/categories/DNS/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"http://devlog.site/tags/DNS/"},{"name":"DNSレコード","slug":"DNSレコード","permalink":"http://devlog.site/tags/DNSレコード/"}]},{"title":"matplotlibを少しだけ","slug":"matplotlib","date":"2016-12-02T15:00:00.000Z","updated":"2016-12-09T13:08:15.000Z","comments":true,"path":"python/matplotlib/","link":"","permalink":"http://devlog.site/python/matplotlib/","excerpt":"matplotlibについて調べてみた引き続き「ゼロから作るディープラーニング」を読んでいます。まだまだ序盤ですが、そこで出てきたのがmatplotlib。どんなものか調べてみました。自分の為の簡単なメモですのであしからず。","content":"matplotlibについて調べてみた引き続き「ゼロから作るディープラーニング」を読んでいます。まだまだ序盤ですが、そこで出てきたのがmatplotlib。どんなものか調べてみました。自分の為の簡単なメモですのであしからず。 matplotlibとはPythonでグラフを描画するときに便利なライブラリです。NumPyなどと組み合わせてデータの可視化に使われます。Pythonで機械学習やる場合は必須なライブラリみたいです。 公式のギャラリーを見ると色々できる見たいですね。 試してみた早速試してみた。前回ディープラーニングの勉強の為に環境は作ってあるので既にインストールは終わっています。 簡単なsin関数をグラフに描画してみました。 123456789In [1]: import numpy as npIn [2]: import matplotlib.pymatplotlib.pylab matplotlib.pyparsing matplotlib.pyplot In [2]: import matplotlib.pyplot as pltIn [3]: x = np.arange(0, 6, 1)In [4]: y = np.sin(x)In [5]: plt.plot(x, y)Out[5]: [&lt;matplotlib.lines.Line2D at 0x110738e10&gt;]In [6]: plt.show() show()を実行するとグラフが描画されます。 次に線グラフではなくプロットにしてみましょう。plot()の第三引数にオプションを指定できるみたいで、&quot;o&quot;とすることでプロットのグラフになります。 12345In [3]: x = np.random.randn(30)In [4]: y = np.sin(x) + np.random.randn(30)In [5]: plt.plot(x, y, &quot;o&quot;)Out[5]: [&lt;matplotlib.lines.Line2D at 0x110709e48&gt;]In [6]: plt.show() 簡単にグラフが描画できましたね。 タイトルや軸にラベルをつけてみたグラフにタイトルや軸の名前をつけることもできるみたいです。 123456789101112131415161718In [1]: import numpy as npIn [3]: import matplotlib.pyplot as pltIn [4]: x = np.arange(0, 6, 0.1)In [5]: y1 = np.sin(x)In [6]: y2 = np.cos(x)In [7]: plt.plot(x, y1, label=&quot;sin&quot;)Out[7]: [&lt;matplotlib.lines.Line2D at 0x110723160&gt;]In [8]: plt.plot(x, y2, linestyle=&quot;--&quot;, label=&quot;cos&quot;)Out[8]: [&lt;matplotlib.lines.Line2D at 0x110723cf8&gt;]In [9]: plt.xlabel(&quot;x&quot;)Out[9]: &lt;matplotlib.text.Text at 0x10a2be0b8&gt;In [10]: plt.ylabel(&quot;y&quot;)Out[10]: &lt;matplotlib.text.Text at 0x1106e2780&gt;In [11]: plt.title(&apos;sin &amp; cos&apos;)Out[11]: &lt;matplotlib.text.Text at 0x1106f95c0&gt;In [12]: plt.legend()Out[12]: &lt;matplotlib.legend.Legend at 0x110723c18&gt;In [13]: plt.show() plt.savefig(&quot;イメージ名.png&quot;)とすることでファイルとして保存することもできるみたいです。 画像の読み込みmatplotlibのimageモジュールを使用することで画像を読み込むこともできるようです。先ほど保存した画像を読み込んでみたいと思います。 12345In [29]: from matplotlib.image import imreadIn [30]: img = imread(&quot;イメージ名.png&quot;)In [31]: plt.imshow(img)Out[31]: &lt;matplotlib.image.AxesImage at 0x1115d0b38&gt;In [32]: plt.show() もっと複雑なことが色々できるみたいですが、一旦この辺りで終わり。","categories":[{"name":"python","slug":"python","permalink":"http://devlog.site/categories/python/"}],"tags":[{"name":"プログラミング","slug":"プログラミング","permalink":"http://devlog.site/tags/プログラミング/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"matplotlib","slug":"matplotlib","permalink":"http://devlog.site/tags/matplotlib/"}]},{"title":"NumPyを試してみた","slug":"numpy","date":"2016-12-01T15:00:00.000Z","updated":"2016-12-01T17:20:33.000Z","comments":true,"path":"python/numpy/","link":"","permalink":"http://devlog.site/python/numpy/","excerpt":"NumPyについて最近読み始めた「ゼロから作るDeep Learning」という本の最初にNumPyのことについて書かれていたので忘れないうちにメモしておきます。 NumPyとは？NumPyはPythonの数値計算数のためのライブラリで、高度な数学アルゴリズムや配列を操作するのに便利なメソッドが多く用意されており、その上パフォーマンスも良いという優れもののようです。ディープラーニングの実装にはよく使われるそうです。","content":"NumPyについて最近読み始めた「ゼロから作るDeep Learning」という本の最初にNumPyのことについて書かれていたので忘れないうちにメモしておきます。 NumPyとは？NumPyはPythonの数値計算数のためのライブラリで、高度な数学アルゴリズムや配列を操作するのに便利なメソッドが多く用意されており、その上パフォーマンスも良いという優れもののようです。ディープラーニングの実装にはよく使われるそうです。 AnacondaディストリビューションのインストールNumPyを使うにはAnacondaディストリビューションを使うことをお進められたので、インストールしてみました。pyenvでまずはインストールできる一覧を確認 12345678pyenv install --list... anaconda3-2.4.1 anaconda3-2.5.0 anaconda3-4.0.0 anaconda3-4.1.0 anaconda3-4.1.1... 今回は最新の3-4.1.1をインストールしました。 1pyenv install anaconda3-4.1.1 インストールできたか確認 1234567pyenv versions system 2.7.11* 2.7.11/envs/tensorflow0.10 (set by /Users/hoge/.pyenv/version) 3.5.1 anaconda3-4.1.1 tensorflow0.10 anacondaいますね。切り替えます。 1pyenv global anaconda3-4.1.1 これで切り替わったのでNumPyが使えますね。 NumPyを試してみるNumPyが使えるようになったので早速試してみましょう。iPythonで対話的に確認してみました。import nuと入力した後にTABキーでnumpyがいますね 12In [1]: import nunumba numbers numexpr numpy 配列の計算をしてみました。NumPyで配列を扱うにはarray()を使用します。 123456In [2]: x = np.array([1.0,2.0,3.0])In [3]: y = np.array([2.0,4.0,6.0])In [4]: x + yOut[4]: array([ 3., 6., 9.])In [5]: x * yOut[5]: array([ 2., 8., 18.]) 配列の要素数が同じ時はそれぞれの格要素同士で計算が行われるようです。要素数が違う場合はエラーになってしまします。 ブロードキャスト先ほど、配列の計算は要素数が同じものでないとエラーになると書きましたが、例外もあります。ブロードキャストという機能があり、形状が異なる配列同士でも計算を行うことができます。 例えばこんな計算はできます。 12345In [6]: A = np.array([[1,2],[3,4]])In [7]: A * 10Out[7]: array([[10, 20], [30, 40]]) 2次元配列のAに対してスカラ値の10を掛け合わせています。この場合はブロードキャスト機能により、スカラ値の10が2x2の要素に自動的に拡大されて[[10,10],[10,10]]として計算されています。 要素へのアクセス要素へのアクセスにはインデックスを指定します。 12345In [8]: B = np.array([[51,50],[9,10],[0,4]])In [10]: print(B[0][0])51In [11]: print(B[0][1])50 条件を指定して要素へアクセス先ほどのBを1次元配列にします。 1234In [19]: B = np.array([[51,50],[9,10],[0,4]])In [20]: B = B.flatten()In [21]: print(B)[51 50 9 10 0 4] flatten()を使用すると多次元配列を1次元配列へ変換することができます。この状態でBの要素の中で15より大きいものを取り出してみましょう。インデックスにB&gt;15を指定します。 12In [22]: B[B&gt;15]Out[22]: array([51, 50]) B&gt;15という式は15より大きい値の場合True、それ以外はFalseになるbooleanの配列を示しており、それをBのインデックスに指定することでTrueが指定された要素を取り出していることになります。 12In [23]: B&gt;15Out[23]: array([ True, True, False, False, False, False], dtype=bool) ndarrayオブジェクトNumPyで配列を扱う際にarray()を使うと書きましたが、これはndarrayというオブジェクトで実は中身はC言語の配列です。Pythonのリスト型と比較して大規模な配列を扱う際の処理効率が非常に良くなっています。 ndarrayはN-dimensional arrayのことでN次元配列を扱えるクラスってことです。まんまですねw NumPyはなぜ速いのか？Pythonはスクリプト言語なので静的言語よりは遅くなりますが、NumPyはndarrayのように主な実装をCやC++でか書いているので速いんです。 終わり。","categories":[{"name":"python","slug":"python","permalink":"http://devlog.site/categories/python/"}],"tags":[{"name":"プログラミング","slug":"プログラミング","permalink":"http://devlog.site/tags/プログラミング/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"NumPy","slug":"NumPy","permalink":"http://devlog.site/tags/NumPy/"}]},{"title":"gitエイリアス","slug":"git-alias","date":"2016-11-30T15:00:00.000Z","updated":"2016-12-09T13:07:06.000Z","comments":true,"path":"git/git-alias/","link":"","permalink":"http://devlog.site/git/git-alias/","excerpt":"gitエイリアスgitはたくさんのコマンドがあってオプションも盛りだくさんなので毎度忘れてしまうし、いちいち打つのが大変なのでそんな時はgitエイリアスが便利です。","content":"gitエイリアスgitはたくさんのコマンドがあってオプションも盛りだくさんなので毎度忘れてしまうし、いちいち打つのが大変なのでそんな時はgitエイリアスが便利です。 .gitconfigファイルで指定.gitconfigファイルに以下のようにaliasセクションに短縮形 = 展開形というふうに書きます。 12[alias] ai = add -i こんな感じで書きます。 設定しているエイリアス私が設定しているエイリアスですが、ちゃんと見返すと全然使ってないものも結構ありましたw 12345678910111213141516171819202122232425ai =&gt; add -ial =&gt; !git config --get-regexp &apos;^alias\\.&apos; | sed &apos;s/alias\\.\\([^ ]*\\) \\(.*\\)/\\1\\ =&gt; \\2/&apos; | sortbr =&gt; branchch =&gt; checkoutcl =&gt; cleanco =&gt; commitcp =&gt; cherry-pickd1 =&gt; diff HEAD~d2 =&gt; diff HEAD~2d3 =&gt; diff HEAD~3dc =&gt; diff --cacheddn =&gt; diff --name-onlyfi =&gt; !git ls-files | grep -ifa =&gt; fetch --all --prunefe =&gt; fetchgr =&gt; log --graph --all --date=short --pretty=format:&apos;%Cgreen%h %cd %Cblue%cn %Creset%s %Cred%d%Creset&apos;ll =&gt; log --name-status --pretty=oneliners =&gt; resetre =&gt; rebasesh =&gt; showsl =&gt; stash listsp =&gt; stash popss =&gt; stash savest =&gt; statussts =&gt; status -s この機会に少し見直してみようと思います。 どんなエイリアス設定したか忘れてしまったとき色々なエイリアスを設定しているとたまにしか使わないのは忘れがちになってしまうのでそんなときに役に立つのがこれ 1al =&gt; !git config --get-regexp &apos;^alias\\.&apos; | sed &apos;s/alias\\.\\([^ ]*\\) \\(.*\\)/\\1\\ =&gt; \\2/&apos; | sort エイリアスの一覧を表示してくれるエイリアス。.gitconfigをいちいち確認しなくていいので便利です。 その他にもたくさん便利な使い方があるのでエイリアスはどんどん設定して効率化していきたいですね。","categories":[{"name":"git","slug":"git","permalink":"http://devlog.site/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://devlog.site/tags/git/"},{"name":"alias","slug":"alias","permalink":"http://devlog.site/tags/alias/"}]},{"title":"Docker基本コマンド","slug":"docker1","date":"2016-11-29T15:00:00.000Z","updated":"2016-12-09T13:06:49.000Z","comments":true,"path":"docker/docker1/","link":"","permalink":"http://devlog.site/docker/docker1/","excerpt":"Dockerを使うときのメモ先人からDockerの環境を引き継ぐこととなりDockerほぼ使ったことなかったので色々調べたことをメモしておきます。","content":"Dockerを使うときのメモ先人からDockerの環境を引き継ぐこととなりDockerほぼ使ったことなかったので色々調べたことをメモしておきます。 Dockerイメージの検索DockerイメージをDocker Hub上から検索できます。 1docker search [イメージ名] DcokerイメージをダウンロードDocker Hub上からイメージをダウンロードします 1docker pull [イメージ名] 取得したDockerイメージの確認pullしてきたイメージの一覧を確認できる 1docker images 起動中のコンテナの一覧を確認-aを付けると停止中のコンテナも取得できる 1docker ps -a DockerfileからDockerイメージを構築1docker build Dockerイメージからコンテナを作成1docker create [イメージ名] Dockerコンテナをスタート1docker start [コンテナ名] Dockerコンテナのストップ1docker stop [コンテナ名] Dcokerコンテナの削除1docker rm [コンテナ名] Dockerビルド時の履歴を確認1docker history [IMAGE] Dockerのコンテナで動作中のシェルへの接続方法動作中のDockerにシェルでつないで色々いじりたいとき 1docker exec -it [コンテナ名] /bin/bash Dockerコンテナのログを確認1docker logs [コンテナ名] Dockerイメージの削除1docker rmi [IMAGE]","categories":[{"name":"Docker","slug":"docker","permalink":"http://devlog.site/categories/docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://devlog.site/tags/Docker/"}]},{"title":"TensorFlowの基本的なAPI1","slug":"tensorflow5","date":"2016-11-28T15:00:00.000Z","updated":"2016-11-28T15:59:32.000Z","comments":true,"path":"tensorflow/tensorflow5/","link":"","permalink":"http://devlog.site/tensorflow/tensorflow5/","excerpt":"TensorFlowのリファレンスを確認してみたネットにはTensorFlowのサンプルコードが山ほどあるので読んで勉強したい！と思ったのですが、APIをまだ全然理解していないので今回は基礎的なAPIのリファレンスを確認してみました。公式のリファレンスはこちら Pythonの対話モードでAPIを実行してみました。 123python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; sess = tf.Session()","content":"TensorFlowのリファレンスを確認してみたネットにはTensorFlowのサンプルコードが山ほどあるので読んで勉強したい！と思ったのですが、APIをまだ全然理解していないので今回は基礎的なAPIのリファレンスを確認してみました。公式のリファレンスはこちら Pythonの対話モードでAPIを実行してみました。 123python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; sess = tf.Session() zeros123456789101112131415161718192021222324252627282930&gt;&gt;&gt; sess.run(tf.zeros(3))array([ 0., 0., 0.], dtype=float32)&gt;&gt;&gt; sess.run(tf.zeros([3,3]))array([[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], dtype=float32)&gt;&gt;&gt; sess.run(tf.zeros([3,3,3]))array([[[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]], dtype=float32)&gt;&gt;&gt; sess.run(tf.zeros([3,3], dtype=tf.int32))array([[0, 0, 0], [0, 0, 0], [0, 0, 0]], dtype=int32)&gt;&gt;&gt; sess.run(tf.zeros([3,3], &quot;int32&quot;))array([[0, 0, 0], [0, 0, 0], [0, 0, 0]], dtype=int32) 0埋めされたTensorを作成してくれるAPIですね。第二引数でdtype=の後にデータタイプを指定できるようです。dtype=ではなく文字列として”int32”としてもいいみたいです。指定しないとデフォルトでtf.float32データタイプになるようです。 zeros_like123456789101112131415161718192021&gt;&gt;&gt; sess.run(tf.zeros_like(0))0&gt;&gt;&gt; sess.run(tf.zeros_like([1]))array([0], dtype=int32)&gt;&gt;&gt; sess.run(tf.zeros_like([1,2]))array([0, 0], dtype=int32)&gt;&gt;&gt; sess.run(tf.zeros_like([[1,2],[3,4]]))array([[0, 0], [0, 0]], dtype=int32)&gt;&gt;&gt; sess.run(tf.zeros_like([[1,2],[3,4],[5,6]]))array([[0, 0], [0, 0], [0, 0]], dtype=int32)&gt;&gt;&gt; sess.run(tf.zeros_like([[1,2],[3,4]], &quot;float32&quot;))array([[ 0., 0.], [ 0., 0.]], dtype=float32) zeros_likeは第一引数と同じ要素数のTensorを0埋めして作成してくるようです。zerosと同様にデータタイプの指定もできますね。ただzerosの場合はデフォルトでtf.float32だったのが、zeros_likeはデフォルトはtf.int32になっていますね。なんでだろう？？ ones1234567&gt;&gt;&gt; sess.run(tf.ones([3]))array([ 1., 1., 1.], dtype=float32)&gt;&gt;&gt; sess.run(tf.ones([3,3]))array([[ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.]], dtype=float32) 基本的にzerosと同様ですね。zerosが0に対してonesは1埋めされたTensorを作成してくるAPIですね。データタイプの指定も前述のAPIと同様のようですね。 ones_like12345678&gt;&gt;&gt; sess.run(tf.ones_like(0))1&gt;&gt;&gt; sess.run(tf.ones_like([1]))array([1], dtype=int32)&gt;&gt;&gt; sess.run(tf.ones_like([1,2], &quot;float32&quot;))array([ 1., 1.], dtype=float32) こちらもzeros_likeと同様で要素が0でなく1で埋められているだけの違いですね。 fill12345678910111213&gt;&gt;&gt; sess.run(tf.fill([],3))3&gt;&gt;&gt; sess.run(tf.fill([3],3))array([3, 3, 3], dtype=int32)&gt;&gt;&gt; sess.run(tf.fill([3,3],3))array([[3, 3, 3], [3, 3, 3], [3, 3, 3]], dtype=int32)&gt;&gt;&gt; sess.run(tf.fill([3], 3.5))array([ 3.5, 3.5, 3.5], dtype=float32) fillは第一引数で指定した要素数のTensorを第二引数で指定した値で埋めて返してくれるAPIのようです。 constant12345678910111213141516&gt;&gt;&gt; sess.run(tf.constant(1.5))1.5&gt;&gt;&gt; sess.run(tf.constant([1]))array([1], dtype=int32)&gt;&gt;&gt; sess.run(tf.constant([1.5, 2]))array([ 1.5, 2. ], dtype=float32)&gt;&gt;&gt; sess.run(tf.constant([[1.5, 2],[3, 4]], &quot;float32&quot;))array([[ 1.5, 2. ], [ 3. , 4. ]], dtype=float32) &gt;&gt;&gt; sess.run(tf.constant(1.5, &quot;float32&quot;,[2,2]))array([[ 1.5, 1.5], [ 1.5, 1.5]], dtype=float32) 定数のTensorを生成するAPIのようですね。第三引数にSharpを指定することも出来ます。 極々基礎的なAPIを確認してみました。今後も使っていてわからないものや気になったAPIをチェックしていきたいと思います。","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://devlog.site/categories/tensorflow/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://devlog.site/tags/TensorFlow/"}]},{"title":"Tensorとは何か？","slug":"tensorflow4","date":"2016-11-27T15:00:00.000Z","updated":"2016-11-28T00:55:12.000Z","comments":true,"path":"tensorflow/tensorflow4/","link":"","permalink":"http://devlog.site/tensorflow/tensorflow4/","excerpt":"TensorFlowのTensorって何？こちらの記事でオペレーションが扱うデータのことをTensorと書きましたが、このTensorって一体何なんでしょう？今回はこのTensorについてもっと詳しく調べてみたいと思います。 公式サイトの説明はこちらになります。","content":"TensorFlowのTensorって何？こちらの記事でオペレーションが扱うデータのことをTensorと書きましたが、このTensorって一体何なんでしょう？今回はこのTensorについてもっと詳しく調べてみたいと思います。 公式サイトの説明はこちらになります。 TensorFlowのTensorはデータ構造TensorFlowで言うところのTensorというのは扱うデータ構造のことで、これを使ってを色々なデータを表現しています。このTensorはRankとShape、Data Typesを持っています。 RankとShapeRankは「テンソルの階数」、Shapeは「テンソルの形」のことを言います。 Rank Shape Dimension 例 0 [] 0次元 s = 713 1 [D0] 1次元 v = [1.1,2.2,3.3] 2 [D0, D1] 2次元 m = [[1,2,3],[4,5,6],[7,8,9]] 3 [D0, D1, D2] 3次元 t = [[[1,2,3]],[[4,5,6]],[[7,8,9]]] N [D0,D1, …Dn-1] n次元 このようにRankが0ならShapeは[]となり0次元の値で、Rankが3ならShapeは[D0, D1, D2]で3次元の配列になるってことですね。 Data Types データタイプ 解説 tf.float16 16ビット浮動小数点 tf.float32 32ビット浮動小数点 tf.float64 64ビット浮動小数点 tf.int8 8ビット整数 tf.int16 16ビット整数 tf.int32 32ビット整数 tf.int64 64ビット整数 tf.uint8 符号無し8ビット整数 tf.string 可変長文字列 tf.bool 真偽値 データタイプは格納するデータの型のことですね。 テンソルについてTensorFlowのTensorと一般的にテンソルというと少し違いがあるようです。一般的にテンソルというと数学的なテンソルのことです。wikiから引用すると テンソル（英: tensor, 独: Tensor）とは、線形的な量または線形的な幾何概念を一般化したもので、基底を選べば、多次元の配列として表現できるようなものである。 とあります。ちょっと難しいですが、テンソルは、数学の線形の量を表す概念でのことです。スカラーやベクトルもテンソルの一種になります。 例えば、大きさのみを持つスカラーは階数0のテンソルと表し、同様に力の大きさとその向きを持つベクトルは階数1のテンソルとなります。また加速度ベクトル間の関係などをあらわす線型変換は階数2のテンソルと言います。ん〜難しいですが、こういう概念もきちんと理解していきたいですね。","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://devlog.site/categories/tensorflow/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://devlog.site/tags/TensorFlow/"}]},{"title":"Pythonのwith構文について調べてみた","slug":"python-with","date":"2016-11-26T15:00:00.000Z","updated":"2016-12-02T16:52:25.000Z","comments":true,"path":"python/python-with/","link":"","permalink":"http://devlog.site/python/python-with/","excerpt":"with構文についてTensorFlowでpython書いてるとよく見かけるwith構文ですが、きちんと理解していなかったのでこの機会に調べてみました。簡単なメモです。","content":"with構文についてTensorFlowでpython書いてるとよく見かけるwith構文ですが、きちんと理解していなかったのでこの機会に調べてみました。簡単なメモです。 with構文とは？with構文はファイルの読み書きなど後処理が必要なものに対して安全にその処理を行える機能です。簡単なファイルを開くコードを見てみましょう。 まずはwith構文を使っていないコード 12345678910text = Nonetry: text = open(\"text.txt\", 'w') try: text.write(\"Hello, world!\") except: raisefinally: if text: text.close() 厳密に書こうとすると結構大変ですよね。次にwithを使った書き方についてですが、 12with ファイル読み込み as 変数: ... こんな感じの構文になります。先ほどのファイルを開くコードを書き換えると 12with open(\"text.txt\", 'w') as text: text.write(\"Hello, world!\") すっきりしましたね。これだけでwithを抜けた際にファイルを自動的に閉じてくれます。 withが使えるオブジェクトwith構文はコードをスッキリ簡潔にしてくれるのでいろんなところで使いたいですが、使える場合とそうでない場合があります。 withが使えるのはenterメソッドとexitメソッドの両方が定義されているオブジェクトの場合です。例えばこんなコードを実行してみます。 12345678910111213141516171819202122class Test(): def __init__(self): print '__init__' def __enter__(self): print '__enter__' return self def __exit__(self, *args, **kwargs): print '__exit__' def __del__(self): print '__del__' def say(self): print 'hello'with Test() as obj: obj.say()print 'end' 結果は次のようになります。 123456__init____enter__hello__exit__end__del__ withを使うとenterメソッドとexitメソッドが呼び出されているのがわかると思います。withを使いたい時はenterメソッドとexitメソッドをきちんと定義してあげましょう。 TensorFlowでよく使うwithファイルを開く際に安全にcloseしてくれるwith構文ですが、TensorFlowではよくセッションを使用する際に使われていますね。ということはSessionを安全に閉じてくれてるってことです。 なんでwith構文が使われているんだろうなぁと思っていましたが、そういった理由があったんですね。TensorFlowのリファレンスを見てみるとSessionクラスには確かにenterメソッドとexitメソッドが定義されています。 tf.Session.__enter__()tf.Session.__exit__(exec_type, exec_value, exec_tb) withのネストwithはネストも出来るみたいです。 12with A() as a: with B() as b: このようにネストして書くこともでき、またカンマで繋げても同じ意味になるようです。 1with A() as a, B() as b: 終わり","categories":[{"name":"python","slug":"python","permalink":"http://devlog.site/categories/python/"}],"tags":[{"name":"プログラミング","slug":"プログラミング","permalink":"http://devlog.site/tags/プログラミング/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"}]},{"title":"IPython使ってみた","slug":"ipython1","date":"2016-11-25T15:00:00.000Z","updated":"2016-12-09T13:07:38.000Z","comments":true,"path":"python/ipython1/","link":"","permalink":"http://devlog.site/python/ipython1/","excerpt":"IPython使ってみたTensorFlowを勉強してて出てきたIPythonという言葉…なんかだよく分からなかったので調べてみました。","content":"IPython使ってみたTensorFlowを勉強してて出てきたIPythonという言葉…なんかだよく分からなかったので調べてみました。 IPythonとは？「あいぱいそん」って読むらしいです。Wikiを見てみると IPython (あいぱいそん) はPythonを対話的に実行するためのシェルである。オリジナルのPythonに比較して、型推定を強化し、対話的実行のための文法を追加してあり、コード・ハイライティングおよびタブによる補完が行える。 とあります。要するに、IPythonは対話的に実行できてタブ補完とかしてくれて色とかついて見やすい便利なやつってことっぽいです。まぁ使ってみた方が早そうですねw インストール私の環境はmacでOS X El Capitanです。pythonのバージョンは2.7.11です。 12python -VPython 2.7.11 インストールにはpipコマンドを使用します。 1pip install ipython 起動してみるインストールが終わったら早速起動してみましょう。 1ipython 起動したらimport tと入力してTABキーを押してみましょう。すると 123456In [1]: import t tabnanny terminalcommand this tkColorChooser tkSimpleDialog traceback tarfile termios thread tkCommonDialog toaiff traitlets telnetlib test threading tkFileDialog token ttk &gt; tempfile tests time tkFont tokenize tty tensorflow textwrap timeit tkMessageBox trace turtle こんな感じで候補の一覧が出てきます！これは便利！ちゃんとインポートしたモジュールの中も補完してくれます。 123In [2]: tf.ze tf.zeros tf.zeros_like tf.zeros_initializer tf.zeta 今まではpythonコマンドで対話的に実行してたんですが、これは便利ですね。 便利な機能イントロスペクションオブジェクトに?をつけてやると対象の情報が表示されます。 12345678910In [1]: ipython = &quot;Great!&quot;In [2]: ipython?Type: strString form: Great!Length: 6Docstring: str(object=&apos;&apos;) -&gt; stringReturn a nice string representation of the object.If the argument is a string, the return value is the same object. また関数に??をつけるとソースコードも表示されるようです。 12345678In [1]: get_ipython??Signature: get_ipython()Source: def get_ipython(self): &quot;&quot;&quot;Return the currently running IPython instance.&quot;&quot;&quot; return selfFile: ~/.pyenv/versions/2.7.11/envs/tensorflow0.10/lib/python2.7/site-packages/IPython/core/interactiveshell.pyType: instancemethod マジックコマンドマジックコマンドはIPythonの用の便利コマンドで頭に%がつくものです。公式のドキュメントはこちら 便利そうなコマンドがたくさんありますね。 コマンド 説明 %lsmagic 利用できるマジックコマンドを表示する %hist または %history コマンドの履歴を表示する %paste クリップボードのコードをペーストして実行する %run ファイルに保存されているスクリプトを実行する %time 単一ステートメントの実行時間を測定し表示する %timeit ステートメントを複数回実行して平均実行時間を表示する %save コマンドの実行履歴をファイルに保存する %reset 変数や名前空間などをクリアする 特に%saveは良さそうですね。IPythonでああでもない、こうでもないって適当に試した履歴をファイルに保存しておきたいってことは多そうです。 1In [21]: %save save.py 1-20 こんな感じでファイルに保存できるようです。 終了終了するときはexitで抜けられます。 1In [1]: exit TensorFlowのInteractiveSession今後IPythonをTensorFlowの勉強に使いたいと思いますが、そんな時に便利なのが、InteractiveSessionです。TensorFlowはまずグラフを作り、Sessionを実行するという流れですが、対話的に作業する際にはグラフを作り終えない状態で、Sessionで実行してみたい場合があります。そこでInteractiveSessionを使うと途中で色々と確認しながら作業を進められるということですね。","categories":[{"name":"python","slug":"python","permalink":"http://devlog.site/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://devlog.site/tags/TensorFlow/"}]},{"title":"機械学習について調べてみた","slug":"machine-learning1","date":"2016-11-24T15:00:00.000Z","updated":"2016-12-09T13:07:58.000Z","comments":true,"path":"machine-learning/machine-learning1/","link":"","permalink":"http://devlog.site/machine-learning/machine-learning1/","excerpt":"機械学習とは何か？今回はそもそも機械学習とは何か？ということを学んでいきたいと思います。","content":"機械学習とは何か？今回はそもそも機械学習とは何か？ということを学んでいきたいと思います。 機械学習とは一言で機械学習についてネットで調べると色々な記事があり、たくさんの専門用語が出てきて調べれば調べるほどよくわかりません。そんな中こちらのサイトが分かりやすかったので、少し引用させていただくと 機械学習とは、データから反復的に学習し、そこに潜むパターンを見つけ出すことです。そして学習した結果を新たなデータにあてはめることで、パターンにしたがって将来を予測することができます。 とのことです。簡潔に言うと機械学習とは「パターン認識」ってことですね。そのパターンを見つけ出す過程のことを学習と呼んでいるようです。 そしてパターンがわかってしまえば、新たなデータがそのパターンに当てはまるかを調べればいいだけなので、予測することができるってわけですね。 機械学習は何の役に立つのか？機械学習はパターンを認識するものということですが、一体どんなことに役立つのでしょうか？いくつか事例を考えてみましょう。 画像認識 ex)写真の特徴のパターンを摘出することで、他の写真と一致するかどうかは判定する 声紋認証 ex)音声の特徴パターンを摘出することで、他人の声と本人の声かどうか判定する おすすめの商品 ex)自分と似た行動パターンを持つ人を摘出することで、購入履歴などからおすすめの商品を判定する 便利な機能にたくさん使われているみたいですね。と、やはりどの事例もパターンを見つけ出して、それを新しいデータに適応して予測するということをやっているようですね。機械学習を学ぶということは、このパターンを見つけ出す様々な方法やその精度を上げるにはどうしたらいいのかということを学ぶってことのようです。 なぜ機械学習が流行っているのか？最近、AlphaGoというプログラムが囲碁で世界トップクラスの棋士に勝ったり、機械学習でGoogle翻訳が良くなったとか、はたまた宇宙人の探索に機械学習を使うとか、そんな機械学習についてのニュースを良く目にしますよね。なぜいま機械学習はこんなに流行っているんでしょう？ 結論から言うとストレージの低価格化とコンピューティング・パワーが上昇した為です。 機械学習のブームは今回が初めてではなく、過去にも何回かありました。流行っては廃れ、また流行っては廃れを繰り返して、またここ最近流行りがきています。 では今こんなにも流行っている機械学習がなぜ過去には廃れてしまったかというと、機械学習は先にも述べたように膨大なサンプルデータとそこからパターンを見つけ出す計算処理を行う必要があったからです。 膨大なサンプルデータを保持しておく為には大容量のストレージが必要ですし、その膨大なサンプルデータからパターンを見つけだす為にはさらに膨大な量の計算処理を行う必要があり、それにはかなりのコンピューティング・パワーを必要とします。昔は今よりストレージの確保も容易ではなくマシーンのパワーもなかった為、ブームは去ってしまったようです。 逆を言うと今はストレージは安く手に入りCPUやGPUの性能も向上しているので個人でも簡単に機械学習を試すことできる為、こんなにも流行っているんですね。 機械学習の進め方流行っているとなればやはりやるしかない、ということで機械学習に取り組んでいきたいのですが、どうゆう風に進めるべきなんでしょうか。機械学習の進め方としてはまず、どんなデータからどんなパターンを摘出したいかを考えるところからはじめるのが良さそうです。それによって機械学習で使用するアルゴリズムや処理が変わると思いますので、まずは機械学習を利用して何がしたいかを考えてみましょう。 そして、何がしたいかが決まればサンプルデータの収集を行い、ストレージに保存、機械学習を行い、学習結果を分析、結果からフィードバックを得て、より精度の高いパターンを摘出するといった流れになると思います。 まとめると 機械学習でどんなことがしたいかを考える サンプルデータの収集を行う 収集したデータを保存する 機械学習でパターンを摘出する 結果を分析する フィードバックからより良く改善していく こんな感じでしょうか。専門的なアルゴリズムや技法は進める中で順々に学んでいこうと思います。いきなり難しい数式の勉強とかやっても挫折しそうなので… 機械学習で大事なところ機械学習はパターン認識だと言いましたが、パターン認識とは具体的にどんなことでしょうか？ 人間は文字を見たとき、例えば「おはよう」という文字を見たとき、これが文字で朝の挨拶だと認識できます。また、犬の写真を見たときにそれが写真で犬が写っていると認識できます。これと同じことを機械が出来るようにするにはどうしたらいいでしょう？ まず人間はどうやって文字や写真を認識しているのか考えてみましょう。詳しくは脳科学の話になってしまうと思うのでわかりませんが、人間は外部からの情報の特徴を摘出し、その意味を正しく認識することによってそれが何であるかを理解しています。 文字には文字の特徴、写真には写真の特徴、それぞれの特徴があります。その特徴を摘出することができれば、機械にも同じことが出来るようになるはずなんです。 そう機械学習で大事なことはこの特徴を見つけ出すことです。 特徴はどうやって決まるの？外部の情報から特徴を見つけ出せれば機械にもそれがどんなものか認識できるということですが、その特徴はどうやって決まっているのでしょうか？例えば「9」という数字の特徴は上に円があって円の右下から尻尾がはえ下がって少し丸まっているといった感じでしょうか。このように数字や文字などは簡単に特徴が思いつくと思います。 では迷惑メールか、そうでない通常のメールかを判断しようとした場合、迷惑メールの特徴とはどういったものでしょうか？“無料”とか”出会い”とか”今すぐ”などといった言葉が多く含まれればといった感じでしょうか？これは少し難しいですよね。 ですが機械はどういった特徴があるものが迷惑メールなのかという、最初の基準となるデータがなければ学習をスタートすることはできません。つまり機械学習では対象のデータがどんな意味を持つかということは人間が決めなければならないのです。 ディープラーニング機械学習では人間が特徴を決める必要があると先ほど書きましたが、実はその特徴すら機械が見つけ出すことも可能なんです。それが機械学習の一種であるディープラーニング(深層学習)です。 このディープラーニングは様々な分野で活用されており、車の自動運転や冒頭でも書いたAlphaGoにも利用されており今後より研究開発が進むと考えられています。","categories":[{"name":"機械学習","slug":"machine-learning","permalink":"http://devlog.site/categories/machine-learning/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"ディープラーニング","slug":"ディープラーニング","permalink":"http://devlog.site/tags/ディープラーニング/"}]},{"title":"TensorFlowの基礎","slug":"tensorflow3","date":"2016-11-23T15:00:00.000Z","updated":"2016-11-26T15:53:27.000Z","comments":true,"path":"tensorflow/tensorflow3/","link":"","permalink":"http://devlog.site/tensorflow/tensorflow3/","excerpt":"TensorFlow基礎今回はTensorFlowの計算処理の流れを見ていきたいと思います。 TensorFlowの計算処理の流れ前回のTensorFlowで四則演算をやってみたでも少しだけ書きましたが、ざっくりオペレーションを先に定義し、セッションを使用してそれを実行するという流れになります。このオペレーションやセッションとはどんなものなんでしょうか？","content":"TensorFlow基礎今回はTensorFlowの計算処理の流れを見ていきたいと思います。 TensorFlowの計算処理の流れ前回のTensorFlowで四則演算をやってみたでも少しだけ書きましたが、ざっくりオペレーションを先に定義し、セッションを使用してそれを実行するという流れになります。このオペレーションやセッションとはどんなものなんでしょうか？ もう少し詳しく調べてみると、TensorFlowでは計算処理にグラフを用いるとのことです。グラフというのはエクセルとかでよく見る折れ線グラフや円グラフのことではなく、こちらのwikiのグラフ理論のことらしいです。 グラフはノードとエッジから構成されるデータ構造のことです。またTensorFlowにおいてのノードはop(オペレーション)と呼ばれ、どうやら一つの計算処理に対応しているとのこと。オペレーションというのは簡単に言うと何かしらの計算処理を行う一つの処理ブロックということのようです。 このopはTensor(テンソル)と呼ばれる行列形式のデータを受け取り、何かしらの計算処理を行い、結果を次のopへ渡していきます。次のopでも受け取った行列形式のデータを使用し、同じように計算処理を行いさらに次のopへ結果を渡します。このように次々にopにデータを受け渡し計算処理を行うことで、最終的な結果を得ることができるという流れです。 次に先ほど出てきたエッジについてです。エッジはノードとノードを繋ぐものでデータをどのノードからどのノードへ受け渡すかを決めるものです。単純にノードで処理した結果を次にどのノードで処理されるかというだけのようですね。 最後にセッションについてです。TensorFlowでは各opごとにCPUコアやGPUコアのリソースをどの程度割り当てるかを指定することができます。パワーを必要とする計算処理には多くのリソースを割り当て、簡単な処理には少ないリソースで済ませるという割り振りができるようでうす。この割り当てを担うのがセッションのようです。そしてセッションは各opの実行も行います。 簡単なコードを見てみましょう。 1234567891011121314151617181920import tensorflow as tf# 定数の定義const = tf.constant(2)const1 = tf.constant(3)const2 = tf.constant(4)# add_opノード(op)を定義add_op = tf.add(const, const1)# add_op1ノード(op)を定義、同時にadd_opの結果をadd_op1へ受け渡すエッジadd_op1 = tf.add(add_op, const2)# セッションsess = tf.Session()# add_opの実行sess.run(add_op)# add_op1の実行、結果をresultへ格納result = sess.run(add_op1)print(result) 足し算を2回行うだけの処理です。実行すると9が出力されると思います。コメントでコード中に注釈を入れているのでわかると思いますが、それぞれがノード(op)、エッジ、セッションになります。 これをtensorboardでグラフ出力してみるとこんな感じになります。 オペレーションAddとAdd_1がエッジで繋がれ、AddにはConst、Const_1が、Add_1にはConst_2が入力として渡されているのがわかりますね。なんとなくTensorFlowの計算処理の流れがわかった気がします！ TensorBoardについて先ほど出てきたTensorBoardとは何かというと、TensorFlowに搭載されている可視化ツールのことです。TensorBoardを使用することでグラフを可視化でき、ブラウザで確認することができます。 TensorBoardでグラフ出力するには以下のコードを追加します。 1tf.train.SummaryWriter('./', sess.graph) 追記したファイルを実行するとTensorBoard用のファイルが生成されます。TensorBoard用のファイルが生成されたら、次のコマンドを実行します。 1tensorboard --logdir=[TensorBoard用のファイルがあるディレクトリ] ブラウザでlocalhost:6006にアクセスするとTensorBoardが立ち上がっていることが確認できると思います。TensorBoardは便利な使い方が色々あるみたいなので今後もっと詳しく調べてみたいと思います。 今回はここまでです。次回はTensorFlowを使う上でもっと基本的な機械学習とは何かについて学んでいこうと思います。","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://devlog.site/categories/tensorflow/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://devlog.site/tags/TensorFlow/"}]},{"title":"TensorFlowで四則演算をやってみた","slug":"tensorflow2","date":"2016-11-22T15:00:00.000Z","updated":"2016-11-26T15:53:15.000Z","comments":true,"path":"tensorflow/tensorflow2/","link":"","permalink":"http://devlog.site/tensorflow/tensorflow2/","excerpt":"TensorFlowで四則演算をやってみた前回環境を整えたので、今回はTensorFlowで四則演算を行ってみました。 はじめにTensorFlow全くの初心者ですので、右も左もわかってません。間違ったこともたくさん書いてると思います。基本的に自分の為にメモしておく程度なのであしからずです。 四則演算まずはTensorFlowで四則演算を行ってみたいと思います。こんな感じのコードになります。","content":"TensorFlowで四則演算をやってみた前回環境を整えたので、今回はTensorFlowで四則演算を行ってみました。 はじめにTensorFlow全くの初心者ですので、右も左もわかってません。間違ったこともたくさん書いてると思います。基本的に自分の為にメモしておく程度なのであしからずです。 四則演算まずはTensorFlowで四則演算を行ってみたいと思います。こんな感じのコードになります。 1234567891011121314151617181920212223242526272829import tensorflow as tf# 定数宣言const1 = tf.constant(2)const2 = tf.constant(3)# 足し算オペレーションadd_op = tf.add(const1, const2)# セッションオブジェクトsess = tf.Session()result = sess.run(add_op)print(result)# 引き算オペレーションsub_op = tf.sub(const1, const2)result = sess.run(sub_op)print(result)# 掛け算オペレーションmul_op = tf.mul(const1, const2)result = sess.run(mul_op)print(result)# 割り算オペレーションdiv_op = tf.div(const1, const2)result = sess.run(div_op)print(result) これを適当な名前(今回はmath.py)で保存して実行すると 12345python math.py5-160 と出力されます。普通の四則演算のコードと全然違いますよね。1つずつ解説していきましょう。 1行目 1import tensorflow as tf これはtensorflow moduleをインポートして、それをtfとして使用するということです。 4行目 1const1 = tf.constant(2) const1という定数を宣言し、その定数に2を設定しています。 8行目 1add_op = tf.add(const1, const2) const1とconst2を足し算するオペーレションadd_opを設定 11行目 1sess = tf.Session() セッションの作成 13行目 1result = sess.run(add_op) 定義したオペレーションの実行 足し算以降の引き算、掛け算、割り算はやってることは同じです。とこのように、TensorFlowでは最初に演算するオペレーションを定義し、その後でセッションを使用してその演算を行うという流れになります。基本的な概念は一旦置いておいて、ざっとこんな感じのようです。 ところで気になった方もいるかもしれませんが、割り算の結果が0になってしまっていますね。2 / 3 なので0.666…になるはず？ですよね。いえ、これは間違いではなく、正しい結果です。tf.divはリファレンスを見てみると テンソルの数値型がint等の浮動小数でない型である場合、小数点以下切り捨て となっているので小数点以下が切り捨てられてしまって0になっているんですね。 小数点以下を切り捨てたくない場合はtf.truedivを使用してます。 123div_op = tf.truediv(const1, const2)result = sess.run(div_op)print(result) こうすることで正しく0.666…が出力されます。 次回は基礎的な概念を少し学んでみたいと思います。","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://devlog.site/categories/tensorflow/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://devlog.site/tags/TensorFlow/"}]},{"title":"TensorFlowの環境を作ってみた","slug":"tensorflow1","date":"2016-11-21T15:00:00.000Z","updated":"2016-11-26T15:52:55.000Z","comments":true,"path":"tensorflow/tensorflow1/","link":"","permalink":"http://devlog.site/tensorflow/tensorflow1/","excerpt":"TensorFlowの環境を作ってみた機械学習の勉強を始めようと思い、今回はTensorFlowの環境を作成してみました。 前提私の環境はmacでOS X El Capitanです。まだmacOS Sierraにはあげてません…TensorFlowのバージョンは0.10を使用します。HomeBrewを使用しますので予めインストールしておいて下さい。","content":"TensorFlowの環境を作ってみた機械学習の勉強を始めようと思い、今回はTensorFlowの環境を作成してみました。 前提私の環境はmacでOS X El Capitanです。まだmacOS Sierraにはあげてません…TensorFlowのバージョンは0.10を使用します。HomeBrewを使用しますので予めインストールしておいて下さい。 pythonのインストールTensorFlowではpythonを使用するので事前にインストールしておきます。macには一応デフォルトでpythonがインストールされえていますが、TensorFlow用に別バージョンのpythonを使用したいと思います。インストールにはバージョン管理が便利なpyenvを使用しますので先にこちらをインストールしておきます。 1brew install pyenv ~/.bash_profileに以下を追加します。 12export PATH=&quot;$HOME/.pyenv/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot; pyenvのインストールが終わったら現在使用されているpythonを確認してみましょう 12pyenv versions* system (set by /Users/hoge/.pyenv/version) macのデフォルトのpythonになっていますね。それではpythonをインストールしてみましょう。今回は2.7.11と3.5.1をインストールしてみます。 12pyenv install 2.7.11pyenv install 3.5.1 インストールが終わったら、対象のバージョンが追加されているか確認してみましょう。 1234pyenv versions* system (set by /Users/hoge/.pyenv/version) 2.7.11 3.5.1 2.7.11と3.5.1が追加されていることがわかりますね。ただしこのままだとmacにデフォルトで入っているpythonを使用する設定になっていますのでバージョンの切り替えを行います。 12345pyenv global 2.7.11pyenv versions system* 2.7.11 (set by /Users/hoge/.pyenv/version) 3.5.1 globalでバージョンの切り替えを行うことができます。systemに付いていた✳︎マークが2.7.11のところに付いているのがわかると思います。これで2.7.11へ切り替わりました。 pyenv-virtualenvのインストール今回はTensorFlow用の仮想環境を作成してその上でTensorFlowを動かしてみたいと思います。仮想環境作成に便利なpyenv-virtualenvを使用します。まずはインストールから。 1brew install pyenv-virtualenv インストールはbrewコマンドで1発で済みます。楽チンですね。 仮想環境の作成pyenv-virtualenvのインストールが終わったら早速、仮想環境を作成してみたいと思います。 1pyenv virtualenv [pyenvのバージョン] [仮想環境名] このコマンドで仮想環境が作れます。今回はTensorFlowのバージョン0.10を使用するので仮想環境名はtensorflow0.10として作成してみます。 1pyenv virtualenv 2.7.11 tensorflow0.10 作成が終わったらpyenv versionsコマンドをた実行してみましょう 123456pyenv versions system* 2.7.11 (set by /Users/hoge/.pyenv/version) 2.7.11/envs/tensorflow0.10 3.5.1 tensorflow0.10 2.7.11/envs/tensorflow0.10とtensorflow0.10が追加されていることがわかりますね。pyenv globalコマンドでバージョンを切り替えましょう 1pyenv global tensorflow0.10 ここまでで仮想環境の作成が終了です。仮想環境へ入るにはアクティベートコマンドを実行します。 1pyenv activate これで仮想環境へ入ることができます。仮想環境から出る場合は以下のコマンドを実行します。 1pyenv deactivate TensorFlowのインストールここからは先ほど作成した仮装環境上で行って下さい。TensorFlowのインストールにはPyPIを使用します。PyPIはPythonのパッケージ管理ツールで、今回使用するpython2.7.11にはデフォルトでインストールされています。コマンドはpipになります。 12pip -Vpip 9.0.1 from /Users/hoge/.pyenv/versions/2.7.11/envs/tensorflow0.10/lib/python2.7/site-packages (python 2.7) PyPIを使用してTensorFlowをインストールするのですが、TensorFlowはPyPIのパッケージには登録されていないのでURLを指定してインストールを行います。 またTensorFlowにはPC環境に応じたバージョンがいくつかあり、ご自身のPC環境に応じたバージョンを使用して下さい。TensorFlow Pip installationこちらから確認できます。 PC環境の違いはGPUがあるかないか、OSはLinuxかMacか、pythonは2.7か3.4もしくは3.5かといった違いです。私の場合はGPUなし、Mac、python2.7になりますので以下のようにインストールを行いました。 12export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0-py2-none-any.whlpip install --upgrade $TF_BINARY_URL これでTensorFlowのインストールは終了です。 TensorFlowの動作確認動作確認は公式サイトにもあるようにコマンドラインからpythonコマンドで行います。 123456789101112$ python...&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)&gt;&gt;&gt; sess = tf.Session()&gt;&gt;&gt; print(sess.run(hello))Hello, TensorFlow!&gt;&gt;&gt; a = tf.constant(10)&gt;&gt;&gt; b = tf.constant(32)&gt;&gt;&gt; print(sess.run(a + b))42&gt;&gt;&gt; これで無事にTensorFlowが動作していることが確認できました。今後はこのTensorFlowで遊んでみたいと思います。","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://devlog.site/categories/tensorflow/"}],"tags":[{"name":"機械学習","slug":"機械学習","permalink":"http://devlog.site/tags/機械学習/"},{"name":"python","slug":"python","permalink":"http://devlog.site/tags/python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://devlog.site/tags/TensorFlow/"}]},{"title":"Hexoでブログをはじめてみた後編","slug":"Hexo-Blog-Start-3","date":"2016-11-20T15:00:00.000Z","updated":"2016-12-09T13:05:58.000Z","comments":true,"path":"hexo/Hexo-Blog-Start-3/","link":"","permalink":"http://devlog.site/hexo/Hexo-Blog-Start-3/","excerpt":"Hexoでブログをはじめてみた-中編の続きです。 Github Pagesにブログを公開できたら過ぎに記事をポストしてみます。","content":"Hexoでブログをはじめてみた-中編の続きです。 Github Pagesにブログを公開できたら過ぎに記事をポストしてみます。 記事の作成記事の作成にはhexoコマンドを使用します。 1hexo new post [記事のタイトル] するとsorce/_post/配下に[記事のタイトル].mdファイルが作成されます。次にこの.mdファイルをマークダウンで内容を記述します。内容が書き終わったら、ビルトインサーバを立ち上げて、プレビューしてみましょう 1hexo s 確認ができたら前回と同様にGithub Pageへ公開する際のコマンドを実行すると、新しく記事を公開することができます。 1hexo d -g ここまでが記事を公開する流れになります。 テーマのカスタマイズhexoにはたくさんテーマがありますが、基本的にどれも設定ファイルとEJSテンプレートを修正することでテーマを自分なりにカスタマイズすることができます。 ejsとはいうゆるテンプレートエンジンで設定ファイルから値を読み込み、HTMLを生成するために使用されます。他のテンプレートエンジンを使ったことがある人にはかなり学習コストも低くすぐに使いこなせると思います。 私が使用しているicarusの場合、layout.ejsでhtml全体の構成を、その中でそれぞれの要素のejsをインクルードしています。変更したいejsファイルにそれぞれ修正を入れました。 細かい修正内容は省くとして、大まかな部分は設定ファイルの_config.ymlを修正すればいいだけなので、非常に簡単です。 今後自身のブログを始めたいという方にhexoを検討してみるものいいかもしれません。","categories":[{"name":"hexo","slug":"hexo","permalink":"http://devlog.site/categories/hexo/"}],"tags":[{"name":"ブログ","slug":"ブログ","permalink":"http://devlog.site/tags/ブログ/"},{"name":"nvm","slug":"nvm","permalink":"http://devlog.site/tags/nvm/"},{"name":"git","slug":"git","permalink":"http://devlog.site/tags/git/"}]},{"title":"Hexoでブログをはじめてみた中編","slug":"Hexo-Blog-Start-2","date":"2016-11-19T15:00:00.000Z","updated":"2016-12-09T13:05:54.000Z","comments":true,"path":"hexo/Hexo-Blog-Start-2/","link":"","permalink":"http://devlog.site/hexo/Hexo-Blog-Start-2/","excerpt":"Hexoでブログをはじめてみた-前編の続きです。 ビルトインサーバでブログを立ち上げることができたと思います。次にGithub Pagesへブログを公開してみましょう。","content":"Hexoでブログをはじめてみた-前編の続きです。 ビルトインサーバでブログを立ち上げることができたと思います。次にGithub Pagesへブログを公開してみましょう。 設定ファイルの修正とプラグインのインストールGithub Pagesへの公開には設定ファイルの修正が必要です。_config.ymlファイルを修正します。 123456vim _config.ymldeploy: type: git repo: git@github.com:&lt;アカウント名&gt;/&lt;アカウント名&gt;gituhub.io.git branch: master 設定ファイルの修正が終わったらGithubデプロイ用のプラグインをインストールします。 1npm install hexo-deployer-git --save Github Pagesに公開ここまで終わったらあとはデプロイするだけです。 1hexo d -g このコマンドを叩くと1発でGithub Pagesに公開することができます。 テーマの変更Github Pagesへの公開はできましたが、このままだとHexoデフォルトのテーマのままなので変更してみたいと思います。今回はGithubに公開せれているhexo-theme-icarusを使用してみました。テーマはGithubに公開されているもの多いので気に入ったもので試してみて下さい。 まずGitからcloneしてきます。 1git clone git@github.com:ppoffice/hexo-theme-icarus.git theme/icarus clone後、icarus内の設定ファイルをリネイムします。 12cd theme/icarusmv \\_config.yml.example _config.yml 次にHexoの設定ファイルを編集します。設定ファイルのthemeを書き換えます。 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: icarus themeをデフォルトのlandscapeからicarusへ変更します。ここまで終わったら1度Githubへデプロイします。 1hexo d -g これでテーマが変わっていることが確認できると思います。今回はここまでで、次回は記事の作成とテーマのカスタマイズを行います。","categories":[{"name":"hexo","slug":"hexo","permalink":"http://devlog.site/categories/hexo/"}],"tags":[{"name":"ブログ","slug":"ブログ","permalink":"http://devlog.site/tags/ブログ/"},{"name":"nvm","slug":"nvm","permalink":"http://devlog.site/tags/nvm/"},{"name":"git","slug":"git","permalink":"http://devlog.site/tags/git/"}]},{"title":"Hexoでブログをはじめてみた前編","slug":"Hexo-Blog-Start","date":"2016-11-19T12:54:03.000Z","updated":"2016-12-09T13:05:46.000Z","comments":true,"path":"hexo/Hexo-Blog-Start/","link":"","permalink":"http://devlog.site/hexo/Hexo-Blog-Start/","excerpt":"自身の勉強と草を生やす為にHexoとGithub Pagesを使ってブログを書くことにしました。早速、ブログの立ち上げ方をブログに書きたいと思います。まずはローカルでHexoのビルトインサーバの立ち上げまでを行います。","content":"自身の勉強と草を生やす為にHexoとGithub Pagesを使ってブログを書くことにしました。早速、ブログの立ち上げ方をブログに書きたいと思います。まずはローカルでHexoのビルトインサーバの立ち上げまでを行います。 はじめに必要なものとして Git Githubアカウント Github Pages 上記は既に持っている前提です。 Hexoの導入nvmインストールHexoはNode.jsなので、まずはNodeのインストールを行います。Nodeのバージョン管理に便利なnvmを先にインストールします。 1⋊&gt; ~ git clone git://github.com/creationix/nvm.git ~/.nvm/ クローンが終わったら 1⋊&gt; ~ source ~/.nvm/nvm.sh bashで叩かないとエラーが出るかもしれません。普段使ってるfishだとエラーが出ました。 NodeのインストールインストールできるNodeのバージョンを確認をします。 12345678nvm ls-remotev0.1.14v0.1.15v0.1.16v0.1.17v0.1.18v0.1.19... 私はこの当時最新だった4.6.2をインストールしました。 1nvm install 4.6.2 無事インストールが終わりました。 12node -vv4.6.2 Hexoのインストール1npm install -g hexo Hexoのインストールはこれで終了です。簡単！ Hexoでブログを作ってみるHexoのインストールができたらブログを立ち上げてみましょう今回はmyBlogという名前でブログを作成しました。 1hexo init myBlog これで新規作成できました。その後はディレクトリを移動し初期化を行います。 12cd myBlognpm install そしてローカルでサーバを立ち上げてみると 1hexo s http://localhost:4000 にアクセスすると、Hexoブログが表示されていることが確認できると思います。ここまででHexoブログの立ち上げ方","categories":[{"name":"hexo","slug":"hexo","permalink":"http://devlog.site/categories/hexo/"}],"tags":[{"name":"ブログ","slug":"ブログ","permalink":"http://devlog.site/tags/ブログ/"},{"name":"nvm","slug":"nvm","permalink":"http://devlog.site/tags/nvm/"},{"name":"git","slug":"git","permalink":"http://devlog.site/tags/git/"}]}]}